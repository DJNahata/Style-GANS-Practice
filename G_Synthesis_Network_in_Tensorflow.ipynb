{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "G_Synthesis Network in Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLtvFKdPqWDdaW4Q2AwGnd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJNahata/Style-GANS-Practice/blob/master/G_Synthesis_Network_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms-i8AjCrVZd",
        "colab_type": "code",
        "outputId": "4c1ee02d-3f9f-43f2-af73-eee3f22791fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"DJ1\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "DJ1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y0kuM6Wri5b",
        "colab_type": "code",
        "outputId": "5f343661-3d26-4f88-a2da-198d2508617c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UbP_9L0rjXp",
        "colab_type": "code",
        "outputId": "b7fdb2cb-91a1-421a-f326-4d0f58538b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/stylegan/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekfCX_J0XK6r",
        "colab_type": "code",
        "outputId": "2136b8fe-15d3-49dd-92b8-a0ede9a3e6f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "\n",
        "def _blur2d(x, f=[1,2,1], normalize=True, flip=False, stride=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(stride, int) and stride >= 1\n",
        "\n",
        "    # Finalize filter kernel.\n",
        "    f = np.array(f, dtype=np.float32)\n",
        "    if f.ndim == 1:\n",
        "        f = f[:, np.newaxis] * f[np.newaxis, :]\n",
        "    assert f.ndim == 2\n",
        "    if normalize:\n",
        "        f /= np.sum(f)\n",
        "    if flip:\n",
        "        f = f[::-1, ::-1]\n",
        "    f = f[:, :, np.newaxis, np.newaxis]\n",
        "    f = np.tile(f, [1, 1, int(x.shape[1]), 1])\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if f.shape == (1, 1) and f[0,0] == 1:\n",
        "        return x\n",
        "\n",
        "    # Convolve using depthwise_conv2d.\n",
        "    orig_dtype = x.dtype\n",
        "    x = tf.cast(x, tf.float32)  # tf.nn.depthwise_conv2d() doesn't support fp16\n",
        "    f = tf.constant(f, dtype=x.dtype, name='filter')\n",
        "    strides = [1, 1, stride, stride]\n",
        "    x = tf.nn.depthwise_conv2d(x, f, strides=strides, padding='SAME', data_format='NCHW')\n",
        "    x = tf.cast(x, orig_dtype)\n",
        "    return x\n",
        "\n",
        "def _upscale2d(x, factor=2, gain=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "\n",
        "    # Apply gain.\n",
        "    if gain != 1:\n",
        "        x *= gain\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if factor == 1:\n",
        "        return x\n",
        "\n",
        "    # Upscale using tf.tile().\n",
        "    s = x.shape\n",
        "    x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
        "    x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "    x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "    return x\n",
        "\n",
        "def _downscale2d(x, factor=2, gain=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "\n",
        "    # 2x2, float32 => downscale using _blur2d().\n",
        "    if factor == 2 and x.dtype == tf.float32:\n",
        "        f = [np.sqrt(gain) / factor] * factor\n",
        "        return _blur2d(x, f=f, normalize=False, stride=factor)\n",
        "\n",
        "    # Apply gain.\n",
        "    if gain != 1:\n",
        "        x *= gain\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if factor == 1:\n",
        "        return x\n",
        "\n",
        "    # Large factor => downscale using tf.nn.avg_pool().\n",
        "    # NOTE: Requires tf_config['graph_options.place_pruned_graph']=True to work.\n",
        "    ksize = [1, 1, factor, factor]\n",
        "    return tf.nn.avg_pool(x, ksize=ksize, strides=ksize, padding='VALID', data_format='NCHW')\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# High-level ops for manipulating 4D activation tensors.\n",
        "# The gradients of these are meant to be as efficient as possible.\n",
        "\n",
        "def blur2d(x, f=[1,2,1], normalize=True):\n",
        "    with tf.variable_scope('Blur2D'):\n",
        "        @tf.custom_gradient\n",
        "        def func(x):\n",
        "            y = _blur2d(x, f, normalize)\n",
        "            @tf.custom_gradient\n",
        "            def grad(dy):\n",
        "                dx = _blur2d(dy, f, normalize, flip=True)\n",
        "                return dx, lambda ddx: _blur2d(ddx, f, normalize)\n",
        "            return y, grad\n",
        "        return func(x)\n",
        "\n",
        "def upscale2d(x, factor=2):\n",
        "    with tf.variable_scope('Upscale2D'):\n",
        "        @tf.custom_gradient\n",
        "        def func(x):\n",
        "            y = _upscale2d(x, factor)\n",
        "            @tf.custom_gradient\n",
        "            def grad(dy):\n",
        "                dx = _downscale2d(dy, factor, gain=factor**2)\n",
        "                return dx, lambda ddx: _upscale2d(ddx, factor)\n",
        "            return y, grad\n",
        "        return func(x)\n",
        "\n",
        "def downscale2d(x, factor=2):\n",
        "    with tf.variable_scope('Downscale2D'):\n",
        "        @tf.custom_gradient\n",
        "        def func(x):\n",
        "            y = _downscale2d(x, factor)\n",
        "            @tf.custom_gradient\n",
        "            def grad(dy):\n",
        "                dx = _upscale2d(dy, factor, gain=1/factor**2)\n",
        "                return dx, lambda ddx: _downscale2d(ddx, factor)\n",
        "            return y, grad\n",
        "        return func(x)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Get/create weight tensor for a convolutional or fully-connected layer.\n",
        "\n",
        "def get_weight(shape, gain=np.sqrt(2), use_wscale=False, lrmul=1):\n",
        "    fan_in = np.prod(shape[:-1]) # [kernel, kernel, fmaps_in, fmaps_out] or [in, out]\n",
        "    he_std = gain / np.sqrt(fan_in) # He init\n",
        "\n",
        "    # Equalized learning rate and custom learning rate multiplier.\n",
        "    if use_wscale:\n",
        "        init_std = 1.0 / lrmul\n",
        "        runtime_coef = he_std * lrmul\n",
        "    else:\n",
        "        init_std = he_std / lrmul\n",
        "        runtime_coef = lrmul\n",
        "\n",
        "    # Create variable.\n",
        "    init = tf.initializers.random_normal(0, init_std)\n",
        "    return tf.get_variable('weight', shape=shape, initializer=init) * runtime_coef\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Fully-connected layer.\n",
        "\n",
        "def dense(x, fmaps, **kwargs):\n",
        "    if len(x.shape) > 2:\n",
        "        x = tf.reshape(x, [-1, np.prod([d.value for d in x.shape[1:]])])\n",
        "    w = get_weight([x.shape[1].value, fmaps], **kwargs)\n",
        "    w = tf.cast(w, x.dtype)\n",
        "    return tf.matmul(x, w)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Convolutional layer.\n",
        "\n",
        "def conv2d(x, fmaps, kernel, **kwargs):\n",
        "    assert kernel >= 1 and kernel % 2 == 1\n",
        "    w = get_weight([kernel, kernel, x.shape[1].value, fmaps], **kwargs)\n",
        "    w = tf.cast(w, x.dtype)\n",
        "    return tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='SAME', data_format='NCHW')\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Fused convolution + scaling.\n",
        "# Faster and uses less memory than performing the operations separately.\n",
        "\n",
        "def upscale2d_conv2d(x, fmaps, kernel, fused_scale='auto', **kwargs):\n",
        "    assert kernel >= 1 and kernel % 2 == 1\n",
        "    assert fused_scale in [True, False, 'auto']\n",
        "    if fused_scale == 'auto':\n",
        "        fused_scale = min(x.shape[2:]) * 2 >= 128\n",
        "\n",
        "    # Not fused => call the individual ops directly.\n",
        "    if not fused_scale:\n",
        "        return conv2d(upscale2d(x), fmaps, kernel, **kwargs)\n",
        "\n",
        "    # Fused => perform both ops simultaneously using tf.nn.conv2d_transpose().\n",
        "    w = get_weight([kernel, kernel, x.shape[1].value, fmaps], **kwargs)\n",
        "    w = tf.transpose(w, [0, 1, 3, 2]) # [kernel, kernel, fmaps_out, fmaps_in]\n",
        "    w = tf.pad(w, [[1,1], [1,1], [0,0], [0,0]], mode='CONSTANT')\n",
        "    w = tf.add_n([w[1:, 1:], w[:-1, 1:], w[1:, :-1], w[:-1, :-1]])\n",
        "    w = tf.cast(w, x.dtype)\n",
        "    os = [tf.shape(x)[0], fmaps, x.shape[2] * 2, x.shape[3] * 2]\n",
        "    return tf.nn.conv2d_transpose(x, w, os, strides=[1,1,2,2], padding='SAME', data_format='NCHW')\n",
        "\n",
        "def conv2d_downscale2d(x, fmaps, kernel, fused_scale='auto', **kwargs):\n",
        "    assert kernel >= 1 and kernel % 2 == 1\n",
        "    assert fused_scale in [True, False, 'auto']\n",
        "    if fused_scale == 'auto':\n",
        "        fused_scale = min(x.shape[2:]) >= 128\n",
        "\n",
        "    # Not fused => call the individual ops directly.\n",
        "    if not fused_scale:\n",
        "        return downscale2d(conv2d(x, fmaps, kernel, **kwargs))\n",
        "\n",
        "    # Fused => perform both ops simultaneously using tf.nn.conv2d().\n",
        "    w = get_weight([kernel, kernel, x.shape[1].value, fmaps], **kwargs)\n",
        "    w = tf.pad(w, [[1,1], [1,1], [0,0], [0,0]], mode='CONSTANT')\n",
        "    w = tf.add_n([w[1:, 1:], w[:-1, 1:], w[1:, :-1], w[:-1, :-1]]) * 0.25\n",
        "    w = tf.cast(w, x.dtype)\n",
        "    return tf.nn.conv2d(x, w, strides=[1,1,2,2], padding='SAME', data_format='NCHW')\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Apply bias to the given activation tensor.\n",
        "\n",
        "def apply_bias(x, lrmul=1):\n",
        "    b = tf.get_variable('bias', shape=[x.shape[1]], initializer=tf.initializers.zeros()) * lrmul\n",
        "    b = tf.cast(b, x.dtype)\n",
        "    if len(x.shape) == 2:\n",
        "        return x + b\n",
        "    return x + tf.reshape(b, [1, -1, 1, 1])\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Leaky ReLU activation. More efficient than tf.nn.leaky_relu() and supports FP16.\n",
        "\n",
        "def leaky_relu(x, alpha=0.2):\n",
        "    with tf.variable_scope('LeakyReLU'):\n",
        "        alpha = tf.constant(alpha, dtype=x.dtype, name='alpha')\n",
        "        @tf.custom_gradient\n",
        "        def func(x):\n",
        "            y = tf.maximum(x, x * alpha)\n",
        "            @tf.custom_gradient\n",
        "            def grad(dy):\n",
        "                dx = tf.where(y >= 0, dy, dy * alpha)\n",
        "                return dx, lambda ddx: tf.where(y >= 0, ddx, ddx * alpha)\n",
        "            return y, grad\n",
        "        return func(x)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Pixelwise feature vector normalization.\n",
        "\n",
        "def pixel_norm(x, epsilon=1e-8):\n",
        "    with tf.variable_scope('PixelNorm'):\n",
        "        epsilon = tf.constant(epsilon, dtype=x.dtype, name='epsilon')\n",
        "        return x * tf.rsqrt(tf.reduce_mean(tf.square(x), axis=1, keepdims=True) + epsilon)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Instance normalization.\n",
        "\n",
        "def instance_norm(x, epsilon=1e-8):\n",
        "    assert len(x.shape) == 4 # NCHW\n",
        "    with tf.variable_scope('InstanceNorm'):\n",
        "        orig_dtype = x.dtype\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        x -= tf.reduce_mean(x, axis=[2,3], keepdims=True)\n",
        "        epsilon = tf.constant(epsilon, dtype=x.dtype, name='epsilon')\n",
        "        x *= tf.rsqrt(tf.reduce_mean(tf.square(x), axis=[2,3], keepdims=True) + epsilon)\n",
        "        x = tf.cast(x, orig_dtype)\n",
        "        return x\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Style modulation.\n",
        "\n",
        "def style_mod(x, dlatent, **kwargs):\n",
        "    with tf.variable_scope('StyleMod'):\n",
        "        style = apply_bias(dense(dlatent, fmaps=x.shape[1]*2, gain=1, **kwargs))\n",
        "        style = tf.reshape(style, [-1, 2, x.shape[1]] + [1] * (len(x.shape) - 2))\n",
        "        return x * (style[:,0] + 1) + style[:,1]\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Noise input.\n",
        "\n",
        "def apply_noise(x, noise_var=None, randomize_noise=True):\n",
        "    assert len(x.shape) == 4 # NCHW\n",
        "    with tf.variable_scope('Noise'):\n",
        "        if noise_var is None or randomize_noise:\n",
        "            noise = tf.random_normal([tf.shape(x)[0], 1, x.shape[2], x.shape[3]], dtype=x.dtype)\n",
        "        else:\n",
        "            noise = tf.cast(noise_var, x.dtype)\n",
        "        weight = tf.get_variable('weight', shape=[x.shape[1].value], initializer=tf.initializers.zeros())\n",
        "        return x + noise * tf.reshape(tf.cast(weight, x.dtype), [1, -1, 1, 1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jnJWb9HPrHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def minibatch_stddev_layer(x, group_size=4, num_new_features=1):\n",
        "    with tf.variable_scope('MinibatchStddev'):\n",
        "        group_size = tf.minimum(group_size, tf.shape(x)[0])     # Minibatch must be divisible by (or smaller than) group_size.\n",
        "        s = x.shape                                             # [NCHW]  Input shape.\n",
        "        y = tf.reshape(x, [group_size, -1, num_new_features, s[1]//num_new_features, s[2], s[3]])   # [GMncHW] Split minibatch into M groups of size G. Split channels into n channel groups c.\n",
        "        y = tf.cast(y, tf.float32)                              # [GMncHW] Cast to FP32.\n",
        "        y -= tf.reduce_mean(y, axis=0, keepdims=True)           # [GMncHW] Subtract mean over group.\n",
        "        y = tf.reduce_mean(tf.square(y), axis=0)                # [MncHW]  Calc variance over group.\n",
        "        y = tf.sqrt(y + 1e-8)                                   # [MncHW]  Calc stddev over group.\n",
        "        y = tf.reduce_mean(y, axis=[2,3,4], keepdims=True)      # [Mn111]  Take average over fmaps and pixels.\n",
        "        y = tf.reduce_mean(y, axis=[2])                         # [Mn11] Split channels into c channel groups\n",
        "        y = tf.cast(y, x.dtype)                                 # [Mn11]  Cast back to original data type.\n",
        "        y = tf.tile(y, [group_size, 1, s[2], s[3]])             # [NnHW]  Replicate over group and pixels.\n",
        "        return tf.concat([x, y], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nhFfqBok6Bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUaJhPG4k6Ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwHbYVoJk6nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_synthesis12(\n",
        "    dlatents_in,                        # Input: Disentangled latents (W) [minibatch, num_layers, dlatent_size].\n",
        "    dlatent_size        = 512,          # Disentangled latent (W) dimensionality.\n",
        "    num_channels        = 3,            # Number of output color channels.\n",
        "    resolution          = 1024,         # Output resolution.\n",
        "    fmap_base           = 8192,         # Overall multiplier for the number of feature maps.\n",
        "    fmap_decay          = 1.0,          # log2 feature map reduction when doubling the resolution.\n",
        "    fmap_max            = 512,          # Maximum number of feature maps in any layer.\n",
        "    use_styles          = True,         # Enable style inputs?\n",
        "    const_input_layer   = True,         # First layer is a learned constant?\n",
        "    use_noise           = True,         # Enable noise inputs?\n",
        "    randomize_noise     = True,         # True = randomize noise inputs every time (non-deterministic), False = read noise inputs from variables.\n",
        "    nonlinearity        = 'lrelu',      # Activation function: 'relu', 'lrelu'\n",
        "    use_wscale          = True,         # Enable equalized learning rate?\n",
        "    use_pixel_norm      = False,        # Enable pixelwise feature vector normalization?\n",
        "    use_instance_norm   = True,         # Enable instance normalization?\n",
        "    dtype               = 'float32',    # Data type to use for activations and outputs.\n",
        "    fused_scale         = 'auto',       # True = fused convolution + scaling, False = separate ops, 'auto' = decide automatically.\n",
        "    blur_filter         = [1,2,1],      # Low-pass filter to apply when resampling activations. None = no filtering.\n",
        "    structure           = 'auto',       # 'fixed' = no progressive growing, 'linear' = human-readable, 'recursive' = efficient, 'auto' = select automatically.\n",
        "    is_template_graph   = False,        # True = template graph constructed by the Network class, False = actual evaluation.\n",
        "    force_clean_graph   = False,        # True = construct a clean graph that looks nice in TensorBoard, False = default behavior.\n",
        "    **_kwargs):                         # Ignore unrecognized keyword args.\n",
        "\n",
        "    resolution_log2 = int(np.log2(resolution))\n",
        "    assert resolution == 2**resolution_log2 and resolution >= 4\n",
        "    def nf(stage): return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)\n",
        "    def blur(x): return blur2d(x, blur_filter) if blur_filter else x\n",
        "    if is_template_graph: force_clean_graph = True\n",
        "    if force_clean_graph: randomize_noise = False\n",
        "    if structure == 'auto': structure = 'linear' if force_clean_graph else 'recursive'\n",
        "    act, gain = {'relu': (tf.nn.relu, np.sqrt(2)), 'lrelu': (leaky_relu, np.sqrt(2))}[nonlinearity]\n",
        "    num_layers = resolution_log2 * 2 - 2\n",
        "    num_styles = num_layers if use_styles else 1\n",
        "    images_out = None\n",
        "\n",
        "    # Primary inputs.\n",
        "    dlatents_in.set_shape([None, num_styles, dlatent_size])\n",
        "    dlatents_in = tf.cast(dlatents_in, dtype)\n",
        "    with tf.variable_scope('lod', reuse = tf.AUTO_REUSE):\n",
        "        lod_in = tf.cast(tf.get_variable('lod', initializer=np.float32(0), trainable=False), dtype)\n",
        "\n",
        "    # Noise inputs.\n",
        "    noise_inputs = []\n",
        "    if use_noise:\n",
        "      with tf.variable_scope('Noise', reuse=tf.AUTO_REUSE):\n",
        "        for layer_idx in range(num_layers):\n",
        "            res = layer_idx // 2 + 2\n",
        "            shape = [1, use_noise, 2**res, 2**res]\n",
        "            noise_inputs.append(tf.get_variable('noise%d' % layer_idx, shape=shape, initializer=tf.initializers.random_normal(), trainable=False))\n",
        "    \n",
        "    a1 = []\n",
        "    a11 = []\n",
        "    a12 = []\n",
        "    a2 = []\n",
        "    a3 = []\n",
        "    a4 = []\n",
        "    a5 = []\n",
        "    a6 = []\n",
        "    a71 = []\n",
        "    a72 = []\n",
        "    a8 = []\n",
        "    a9 = []\n",
        "    a10 = []\n",
        "\n",
        "    a1.append(dlatents_in)\n",
        "\n",
        "\n",
        "    # Things to do at the end of each layer.\n",
        "    def layer_epilogue(x, a2, a3, a4, a5, a6, layer_idx):\n",
        "        if use_noise:\n",
        "            x = apply_noise(x, noise_inputs[layer_idx], randomize_noise=randomize_noise)\n",
        "            a2.append(x)\n",
        "        x = apply_bias(x)\n",
        "        a3.append(x)\n",
        "        x = act(x)\n",
        "        a4.append(x)\n",
        "        if use_pixel_norm:\n",
        "            x = pixel_norm(x)\n",
        "        if use_instance_norm:\n",
        "            x = instance_norm(x)\n",
        "            a5.append(x)\n",
        "        if use_styles:\n",
        "            x = style_mod(x, dlatents_in[:, layer_idx], use_wscale=use_wscale)\n",
        "            a6.append(x)\n",
        "        return x\n",
        "\n",
        "    # Early layers.\n",
        "    with tf.variable_scope('4x4', reuse = tf.AUTO_REUSE):\n",
        "        if const_input_layer:\n",
        "            with tf.variable_scope('Const'):\n",
        "                x = tf.get_variable('const', shape=[1, nf(1), 4, 4], initializer=tf.initializers.ones())\n",
        "                a1.append(x)\n",
        "                x = layer_epilogue(tf.tile(tf.cast(x, dtype), [tf.shape(dlatents_in)[0], 1, 1, 1]), a2, a3, a4, a5, a6, 0)\n",
        "        else:\n",
        "            with tf.variable_scope('Dense'):\n",
        "                x = dense(dlatents_in[:, 0], fmaps=nf(1)*16, gain=gain/4, use_wscale=use_wscale) # tweak gain to match the official implementation of Progressing GAN\n",
        "                x = layer_epilogue(tf.reshape(x, [-1, nf(1), 4, 4]), 0)\n",
        "        with tf.variable_scope('Conv', reuse = tf.AUTO_REUSE):\n",
        "            x = conv2d(x, fmaps=nf(1), kernel=3, gain=gain, use_wscale=use_wscale)\n",
        "            a1.append(x)\n",
        "            x = layer_epilogue(x, a2, a3, a4, a5, a6, 1)\n",
        "\n",
        "    # Building blocks for remaining layers.\n",
        "    def block(res, a1, a2, a3, a4, a5, a6, a11, a12, x): # res = 3..resolution_log2\n",
        "        with tf.variable_scope('%dx%d' % (2**res, 2**res), reuse = tf.AUTO_REUSE):\n",
        "            with tf.variable_scope('Conv0_up'):\n",
        "                x = upscale2d_conv2d(x, fmaps=nf(res-1), kernel=3, gain=gain, use_wscale=use_wscale, fused_scale=fused_scale)\n",
        "                a11.append(x)\n",
        "                x = blur(x)\n",
        "                a12.append(x)\n",
        "                x = layer_epilogue(x, a2, a3, a4, a5, a6, res*2-4)\n",
        "            with tf.variable_scope('Conv1'):\n",
        "                x = conv2d(x, fmaps=nf(res-1), kernel=3, gain=gain, use_wscale=use_wscale)\n",
        "                a1.append(x)\n",
        "                x = layer_epilogue(x, a2, a3, a4, a5, a6, res*2-3)\n",
        "            return x\n",
        "\n",
        "\n",
        "    def torgb(res, a71, a72, x): # res = 2..resolution_log2\n",
        "        lod = resolution_log2 - res\n",
        "        with tf.variable_scope('ToRGB_lod%d' % lod, reuse = tf.AUTO_REUSE):\n",
        "            x = conv2d(x, fmaps=num_channels, kernel=1, gain=1, use_wscale=use_wscale)\n",
        "            a71.append(x)\n",
        "            x = apply_bias(x)\n",
        "            a72.append(x)\n",
        "            return x\n",
        "\n",
        "    # Fixed structure: simple and efficient, but does not support progressive growing.\n",
        "    if structure == 'fixed':\n",
        "        for res in range(3, resolution_log2 + 1):\n",
        "            x = block(res, x)\n",
        "        images_out = torgb(resolution_log2, x)\n",
        "\n",
        "    # Linear structure: simple but inefficient.\n",
        "    if structure == 'linear':\n",
        "        images_out = torgb(2, a71, a72, x)\n",
        "        for res in range(3, resolution_log2 + 1):\n",
        "            lod = resolution_log2 - res\n",
        "            x = block(res, a1, a2, a3, a4, a5, a6, a11, a12, x)\n",
        "            img = torgb(res, a71, a72, x)\n",
        "            a10.append(img)\n",
        "            images_out = upscale2d(images_out)\n",
        "            with tf.variable_scope('Grow_lod%d' % lod, reuse = tf.AUTO_REUSE):\n",
        "                images_out = tflib.lerp_clip(img, images_out, lod_in - lod)\n",
        "                a8.append(images_out)\n",
        "\n",
        "    # Recursive structure: complex but efficient.\n",
        "    if structure == 'recursive':\n",
        "        def cset(cur_lambda, new_cond, new_lambda):\n",
        "            return lambda: tf.cond(new_cond, new_lambda, cur_lambda)\n",
        "        def grow(x, res, lod):\n",
        "            y = block(res, x)\n",
        "            img = lambda: upscale2d(torgb(res, y), 2**lod)\n",
        "            img = cset(img, (lod_in > lod), lambda: upscale2d(tflib.lerp(torgb(res, y), upscale2d(torgb(res - 1, x)), lod_in - lod), 2**lod))\n",
        "            if lod > 0: img = cset(img, (lod_in < lod), lambda: grow(y, res + 1, lod - 1))\n",
        "            return img()\n",
        "        images_out = grow(x, 3, resolution_log2 - 3)\n",
        "\n",
        "    a9.append(a1)\n",
        "    a9.append(a11)\n",
        "    a9.append(a12)\n",
        "    a9.append(a2)\n",
        "    a9.append(a3)\n",
        "    a9.append(a4)\n",
        "    a9.append(a5)\n",
        "    a9.append(a6)\n",
        "    a9.append(a71)\n",
        "    a9.append(a72)\n",
        "    a9.append(a10)\n",
        "    a9.append(a8)\n",
        "\n",
        "    assert images_out.dtype == tf.as_dtype(dtype)\n",
        "    return a9, tf.identity(images_out, name='images_out')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snm0oaFOk6q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng7e2bcmk5-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYDuo1b8Dhab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_synthesis(\n",
        "    dlatents_in,                        # Input: Disentangled latents (W) [minibatch, num_layers, dlatent_size].\n",
        "    dlatent_size        = 512,          # Disentangled latent (W) dimensionality.\n",
        "    num_channels        = 3,            # Number of output color channels.\n",
        "    resolution          = 1024,         # Output resolution.\n",
        "    fmap_base           = 8192,         # Overall multiplier for the number of feature maps.\n",
        "    fmap_decay          = 1.0,          # log2 feature map reduction when doubling the resolution.\n",
        "    fmap_max            = 512,          # Maximum number of feature maps in any layer.\n",
        "    use_styles          = True,         # Enable style inputs?\n",
        "    const_input_layer   = True,         # First layer is a learned constant?\n",
        "    use_noise           = True,         # Enable noise inputs?\n",
        "    randomize_noise     = True,         # True = randomize noise inputs every time (non-deterministic), False = read noise inputs from variables.\n",
        "    nonlinearity        = 'lrelu',      # Activation function: 'relu', 'lrelu'\n",
        "    use_wscale          = True,         # Enable equalized learning rate?\n",
        "    use_pixel_norm      = False,        # Enable pixelwise feature vector normalization?\n",
        "    use_instance_norm   = True,         # Enable instance normalization?\n",
        "    dtype               = 'float32',    # Data type to use for activations and outputs.\n",
        "    fused_scale         = 'auto',       # True = fused convolution + scaling, False = separate ops, 'auto' = decide automatically.\n",
        "    blur_filter         = [1,2,1],      # Low-pass filter to apply when resampling activations. None = no filtering.\n",
        "    structure           = 'auto',       # 'fixed' = no progressive growing, 'linear' = human-readable, 'recursive' = efficient, 'auto' = select automatically.\n",
        "    is_template_graph   = False,        # True = template graph constructed by the Network class, False = actual evaluation.\n",
        "    force_clean_graph   = False,        # True = construct a clean graph that looks nice in TensorBoard, False = default behavior.\n",
        "    **_kwargs):                         # Ignore unrecognized keyword args.\n",
        "\n",
        "    resolution_log2 = int(np.log2(resolution))\n",
        "    assert resolution == 2**resolution_log2 and resolution >= 4\n",
        "    def nf(stage): return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)\n",
        "    def blur(x): return blur2d(x, blur_filter) if blur_filter else x\n",
        "    if is_template_graph: force_clean_graph = True\n",
        "    if force_clean_graph: randomize_noise = False\n",
        "    if structure == 'auto': structure = 'linear' if force_clean_graph else 'recursive'\n",
        "    act, gain = {'relu': (tf.nn.relu, np.sqrt(2)), 'lrelu': (leaky_relu, np.sqrt(2))}[nonlinearity]\n",
        "    num_layers = resolution_log2 * 2 - 2\n",
        "    num_styles = num_layers if use_styles else 1\n",
        "    images_out = None\n",
        "\n",
        "    # Primary inputs.\n",
        "    dlatents_in.set_shape([None, num_styles, dlatent_size])\n",
        "    dlatents_in = tf.cast(dlatents_in, dtype)\n",
        "    with tf.variable_scope('lod', reuse = tf.AUTO_REUSE):\n",
        "        lod_in = tf.cast(tf.get_variable('lod', initializer=np.float32(0), trainable=False), dtype)\n",
        "\n",
        "    # Noise inputs.\n",
        "    noise_inputs = []\n",
        "    if use_noise:\n",
        "      with tf.variable_scope('Noise', reuse=tf.AUTO_REUSE):\n",
        "        for layer_idx in range(num_layers):\n",
        "            res = layer_idx // 2 + 2\n",
        "            shape = [1, use_noise, 2**res, 2**res]\n",
        "            noise_inputs.append(tf.get_variable('noise%d' % layer_idx, shape=shape, initializer=tf.initializers.random_normal(), trainable=False))\n",
        "\n",
        "    # Things to do at the end of each layer.\n",
        "    def layer_epilogue(x, layer_idx):\n",
        "        if use_noise:\n",
        "            x = apply_noise(x, noise_inputs[layer_idx], randomize_noise=randomize_noise)\n",
        "        x = apply_bias(x)\n",
        "        x = act(x)\n",
        "        if use_pixel_norm:\n",
        "            x = pixel_norm(x)\n",
        "        if use_instance_norm:\n",
        "            x = instance_norm(x)\n",
        "        if use_styles:\n",
        "            x = style_mod(x, dlatents_in[:, layer_idx], use_wscale=use_wscale)\n",
        "        return x\n",
        "\n",
        "    # Early layers.\n",
        "    with tf.variable_scope('4x4', reuse = tf.AUTO_REUSE):\n",
        "        if const_input_layer:\n",
        "            with tf.variable_scope('Const'):\n",
        "                x = tf.get_variable('const', shape=[1, nf(1), 4, 4], initializer=tf.initializers.ones())\n",
        "                x = layer_epilogue(tf.tile(tf.cast(x, dtype), [tf.shape(dlatents_in)[0], 1, 1, 1]), 0)\n",
        "        else:\n",
        "            with tf.variable_scope('Dense'):\n",
        "                x = dense(dlatents_in[:, 0], fmaps=nf(1)*16, gain=gain/4, use_wscale=use_wscale) # tweak gain to match the official implementation of Progressing GAN\n",
        "                x = layer_epilogue(tf.reshape(x, [-1, nf(1), 4, 4]), 0)\n",
        "        with tf.variable_scope('Conv', reuse = tf.AUTO_REUSE):\n",
        "            x = layer_epilogue(conv2d(x, fmaps=nf(1), kernel=3, gain=gain, use_wscale=use_wscale), 1)\n",
        "\n",
        "    # Building blocks for remaining layers.\n",
        "    def block(res, x): # res = 3..resolution_log2\n",
        "        with tf.variable_scope('%dx%d' % (2**res, 2**res), reuse = tf.AUTO_REUSE):\n",
        "            with tf.variable_scope('Conv0_up'):\n",
        "                x = layer_epilogue(blur(upscale2d_conv2d(x, fmaps=nf(res-1), kernel=3, gain=gain, use_wscale=use_wscale, fused_scale=fused_scale)), res*2-4)\n",
        "            with tf.variable_scope('Conv1'):\n",
        "                x = layer_epilogue(conv2d(x, fmaps=nf(res-1), kernel=3, gain=gain, use_wscale=use_wscale), res*2-3)\n",
        "            return x\n",
        "    def torgb(res, x): # res = 2..resolution_log2\n",
        "        lod = resolution_log2 - res\n",
        "        with tf.variable_scope('ToRGB_lod%d' % lod, reuse = tf.AUTO_REUSE):\n",
        "            return apply_bias(conv2d(x, fmaps=num_channels, kernel=1, gain=1, use_wscale=use_wscale))\n",
        "\n",
        "    # Fixed structure: simple and efficient, but does not support progressive growing.\n",
        "    if structure == 'fixed':\n",
        "        for res in range(3, resolution_log2 + 1):\n",
        "            x = block(res, x)\n",
        "        images_out = torgb(resolution_log2, x)\n",
        "\n",
        "    # Linear structure: simple but inefficient.\n",
        "    if structure == 'linear':\n",
        "        images_out = torgb(2, x)\n",
        "        for res in range(3, resolution_log2 + 1):\n",
        "            lod = resolution_log2 - res\n",
        "            x = block(res, x)\n",
        "            img = torgb(res, x)\n",
        "            images_out = upscale2d(images_out)\n",
        "            with tf.variable_scope('Grow_lod%d' % lod, reuse = tf.AUTO_REUSE):\n",
        "                images_out = tflib.lerp_clip(img, images_out, lod_in - lod)\n",
        "\n",
        "    # Recursive structure: complex but efficient.\n",
        "    if structure == 'recursive':\n",
        "        def cset(cur_lambda, new_cond, new_lambda):\n",
        "            return lambda: tf.cond(new_cond, new_lambda, cur_lambda)\n",
        "        def grow(x, res, lod):\n",
        "            y = block(res, x)\n",
        "            img = lambda: upscale2d(torgb(res, y), 2**lod)\n",
        "            img = cset(img, (lod_in > lod), lambda: upscale2d(tflib.lerp(torgb(res, y), upscale2d(torgb(res - 1, x)), lod_in - lod), 2**lod))\n",
        "            if lod > 0: img = cset(img, (lod_in < lod), lambda: grow(y, res + 1, lod - 1))\n",
        "            return img()\n",
        "        images_out = grow(x, 3, resolution_log2 - 3)\n",
        "\n",
        "    assert images_out.dtype == tf.as_dtype(dtype)\n",
        "    return tf.identity(images_out, name='images_out')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oO-95wrk4dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7a0NFaZk4a0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnCZ1xNPDhdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e61iJ2DqCmt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2DocAuMPtC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G1(\n",
        "    dlatents_in,\n",
        "    dlatent_size = 512,\n",
        "    num_channels = 3,\n",
        "    resolution = 256,\n",
        "    fmap_base = 8192,\n",
        "    fmap_decay = 1.0,\n",
        "    fmap_max = 512,\n",
        "    use_style = True,\n",
        "    const_input_layer = True,\n",
        "    use_noise = True,\n",
        "    randomize_noise = True,\n",
        "    nonlinearity = 'lrelu',\n",
        "    use_wscale = True,\n",
        "    use_pixel_norm = False,\n",
        "    use_instance_norm = True,\n",
        "    dtype = 'float32',\n",
        "    fused_scale = True,\n",
        "    blur_filter = [1,2,1],\n",
        "    structure = 'linear',\n",
        "    is_template_graph = False,\n",
        "    force_clean_graph = False,\n",
        "    **_kwargs):\n",
        "    \n",
        "  \n",
        "    resolution_log2 = int(np.log2(resolution))\n",
        "    assert resolution == 2**resolution_log2 and resolution >= 4\n",
        "    def nf(stage): return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)\n",
        "    def blur(x): return blur2d(x, blur_filter) if blur_filter else x\n",
        "    if is_template_graph: force_clean_graph = True\n",
        "    if force_clean_graph: randomize_noise = False\n",
        "    if structure == 'auto': structure = 'linear' if force_clean_graph else 'recursive'\n",
        "    act, gain = {'relu': (tf.nn.relu, np.sqrt(2)), 'lrelu': (leaky_relu, np.sqrt(2))}[nonlinearity]\n",
        "    num_layers = resolution_log2 * 2 - 2\n",
        "    num_styles = num_layers if use_style else 1\n",
        "    images_out = None\n",
        "\n",
        "\n",
        "    #dlatents_in = tf.cast(dlatents_in, dtype)\n",
        "    with tf.variable_scope('lod', reuse=tf.AUTO_REUSE):\n",
        "        lod_in = tf.cast(tf.get_variable('lod', initializer=np.float32(0), trainable=False), dtype)\n",
        "\n",
        "    # Noise inputs.\n",
        "    noise_inputs = []\n",
        "    if use_noise:\n",
        "      with tf.variable_scope('Noise', reuse=tf.AUTO_REUSE):\n",
        "        for layer_idx in range(num_layers):\n",
        "            res = layer_idx // 2 + 2\n",
        "            shape = [1, use_noise, 2**res, 2**res]\n",
        "            noise_inputs.append(tf.get_variable('noise%d' % layer_idx, shape=shape, initializer=tf.initializers.random_normal(), trainable=False))\n",
        "\n",
        "    a1 = []\n",
        "    a11 = []\n",
        "    a2 = []\n",
        "    a3 = []\n",
        "    a4 = []\n",
        "    a5 = []\n",
        "    a6 = []\n",
        "    a71 = []\n",
        "    a72= []\n",
        "    a8 = []\n",
        "    a10 = []\n",
        "\n",
        "    a1.append(dlatents_in)\n",
        "\n",
        "    # Things to do at the end of each layer.\n",
        "    def layer_epilogue(x, a2, a3, a4, a5, a6, a11, layer_idx):\n",
        "        if use_noise:\n",
        "            x = apply_noise(x, noise_inputs[layer_idx], randomize_noise=randomize_noise)\n",
        "            a2.append(x)\n",
        "        x = apply_bias(x)\n",
        "        a3.append(x)\n",
        "        x = act(x)\n",
        "        a4.append(x)\n",
        "        if use_pixel_norm:\n",
        "            x = pixel_norm(x)\n",
        "        if use_instance_norm:\n",
        "            x = instance_norm(x)\n",
        "            a5.append(x)\n",
        "        if use_style:\n",
        "            x = style_mod(x, dlatents_in[:, layer_idx], use_wscale = use_wscale)\n",
        "            a6.append(x)\n",
        "        return x\n",
        "\n",
        "    def block(res, a1, a2, a3, a4, a5, a6, a11, x): # res = 3..resolution_log2\n",
        "        with tf.variable_scope('%dx%d' % (2**res, 2**res), reuse=tf.AUTO_REUSE):\n",
        "            with tf.variable_scope('Conv0_up'):\n",
        "                x = blur(upscale2d_conv2d(x, fmaps=nf(res-1), kernel=3, gain=gain, use_wscale=use_wscale, fused_scale=fused_scale))\n",
        "                a1.append(x)\n",
        "                x = layer_epilogue(x, a2, a3, a4, a5, a6, a11, res*2-4)\n",
        "            with tf.variable_scope('Conv1'):\n",
        "                x = conv2d(x, fmaps=nf(res-1), kernel=3, gain=gain, use_wscale=use_wscale)\n",
        "                a1.append(x)\n",
        "                x = layer_epilogue(x, a2, a3, a4, a5, a6, a11, res*2-3)\n",
        "            return x\n",
        "\n",
        "    def torgb(res, a71, a72,  x): # res = 2..resolution_log2\n",
        "        lod = resolution_log2 - res\n",
        "        with tf.variable_scope('ToRGB_lod%d' % (lod) , reuse = tf.AUTO_REUSE):\n",
        "            x = conv2d(x, fmaps=num_channels, kernel=1, gain=1, use_wscale=use_wscale)\n",
        "            a71.append(x)\n",
        "            x = apply_bias(x)\n",
        "            a72.append(x)\n",
        "            return x\n",
        "\n",
        "    # Early layers.\n",
        "    with tf.variable_scope('4x4', reuse=tf.AUTO_REUSE):\n",
        "        if const_input_layer:\n",
        "            with tf.variable_scope('Const'):\n",
        "                x = tf.get_variable('const', shape=[1, nf(1), 4, 4], initializer=tf.initializers.ones())\n",
        "                a1.append(x)\n",
        "                x = layer_epilogue(tf.tile(tf.cast(x, dtype), [tf.shape(dlatents_in)[0], 1, 1, 1]), a2, a3, a4, a5, a6, a11, 0)\n",
        "        else:\n",
        "            with tf.variable_scope('Dense'):\n",
        "                x = dense(dlatents_in[:, 0], fmaps=nf(1)*16, gain=gain/4, use_wscale=use_wscale) # tweak gain to match the official implementation of Progressing GAN\n",
        "                x = layer_epilogue(tf.reshape(x, [-1, nf(1), 4, 4]), a2, a3, a4, a5, a6, a11, 0)\n",
        "        with tf.variable_scope('Conv'):\n",
        "            x = conv2d(x, fmaps=nf(1), kernel=3, gain=gain, use_wscale=use_wscale)\n",
        "            x = layer_epilogue(x, a2, a3, a4, a5, a6, a11, 1)\n",
        "\n",
        "    if structure == 'fixed':\n",
        "        for res in range(3, resolution_log2 + 1):\n",
        "            x = block(res, a1, a2, a3, a4, a5, a6, x)\n",
        "        images_out = torgb(resolution_log2, a7, x)\n",
        "\n",
        "    if structure == 'linear':\n",
        "        print(\"Structure followed is Linear\")\n",
        "        images_out = torgb(2, a71, a72, x)\n",
        "        a10.append(images_out)\n",
        "        for res in range(3, resolution_log2 + 1):\n",
        "            lod = resolution_log2 - res\n",
        "            x = block(res, a1, a2, a3, a4, a5, a6, a11, x)\n",
        "            img = torgb(res, a71, a72, x)\n",
        "            images_out = upscale2d(images_out)\n",
        "            with tf.variable_scope('Grow_lod%d' % lod, reuse = tf.AUTO_REUSE):\n",
        "                images_out = tflib.lerp_clip(img, images_out, lod_in - lod)\n",
        "                a10.append(images_out)\n",
        "\n",
        "    a8.append(a1)\n",
        "    a8.append(a2)\n",
        "    a8.append(a3)\n",
        "    a8.append(a4)\n",
        "    a8.append(a5)\n",
        "    a8.append(a6)\n",
        "    a8.append(a71)\n",
        "    a8.append(a72)\n",
        "    a8.append(a10)\n",
        "\n",
        "    return a8, tf.identity(images_out, name='images_out')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rQtT224DkKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIDCrC2FDkN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7dg5QDdDkRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPh9HKSnUrWB",
        "colab_type": "code",
        "outputId": "d666a815-2b32-427a-b2fe-2f37f14213e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTGTy5yVQhS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(\"noise.txt\", \"rb\") as fp:   \n",
        "   noise = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkLl12SDQjdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(\"const.txt\", \"rb\") as fp:   \n",
        "   const = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBAUS5-3QlTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open(\"input1.txt\", \"rb\") as fp:   \n",
        "   input1 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU2bSpqrQnPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights1.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights1 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PevJMjxwVNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights2.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights2 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqoUAm0Ltv3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights3.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights3 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-t6ORi8tv80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights4.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights4 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUBLllGmtwFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights5.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights5 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeB_2NfdtwNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights6.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights6 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsQXsELrt5hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights7.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights7 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxEP8DwtZ_QR",
        "colab_type": "code",
        "outputId": "c01b3e94-6aff-4d8e-f332-2df086929b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/stylegan/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQrQC_W5QpHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputx = input1[0]\n",
        "inputx = tf.convert_to_tensor(inputx, dtype = tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1OxpUdT17-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list1, out1 = G_synthesis12(inputx, num_channels = 3, resolution= 256, randomize_noise = False, use_wscale = False, fused_scale=False, structure='linear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1YrIqLl18Cd",
        "colab_type": "code",
        "outputId": "8dab52cc-23e2-4218-833c-339338756d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(out1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 256, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvD9kgld2QEY",
        "colab_type": "code",
        "outputId": "db802b62-d621-4543-ca98-851d9f2891bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNpCGFPa2QHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg6-7Fe02QPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjSc-zIv2QM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ksa3NDk18Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGPufeZHFCVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "o1 = G_synthesis(inputx, num_channels = 3, resolution= 256, randomize_noise = False, use_wscale = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzqOSU8yFCTJ",
        "colab_type": "code",
        "outputId": "ab84d8b1-e36b-47e3-8003-b721a07b9837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(o1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 256, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAhFaFNHIz3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja1N5gXxIz6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJPDR9TQxNM",
        "colab_type": "code",
        "outputId": "8716c1a9-7746-48ce-cd02-bc822854647a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list1, output1 = G1(input, randomize_noise = False, use_wscale = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Structure followed is Linear\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH5EEZJ3IzKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzofILZ7IzQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbS1LrWquHbt",
        "colab_type": "code",
        "outputId": "d02dca65-6f95-4b0f-ef3b-bc6190075cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(output1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 256, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmTkHmtzI05P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwRpepPDI07z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2O5Pv4OQ2oE",
        "colab_type": "code",
        "outputId": "81833edf-dec6-4838-d5b9-f303bc0b949d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv_y6IepQ7iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b1 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Noise')\n",
        "b2 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='4x4/Const')\n",
        "b3 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='4x4/Conv')\n",
        "b4 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='ToRGB_lod6')\n",
        "b51 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='8x8/Conv0_up')\n",
        "b61 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='8x8/Conv1')\n",
        "b71 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='ToRGB_lod5')\n",
        "b52 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='16x16/Conv0_up')\n",
        "b62 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='16x16/Conv1')\n",
        "b72= tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='ToRGB_lod4')\n",
        "b53 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='32x32/Conv0_up')\n",
        "b63 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='32x32/Conv1')\n",
        "b73 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='ToRGB_lod3')\n",
        "b54 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='64x64/Conv0_up')\n",
        "b64 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='64x64/Conv1')\n",
        "b74= tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='ToRGB_lod2')\n",
        "b55 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='128x128/Conv0_up')\n",
        "b65 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='128x128/Conv1')\n",
        "b75 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='ToRGB_lod1')\n",
        "b56 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='256x256/Conv0_up')\n",
        "b66 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='256x256/Conv1')\n",
        "b76= tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='ToRGB_lod0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g66UYtXhUjAs",
        "colab_type": "code",
        "outputId": "8a8ecfef-7d62-415b-cc69-129c5d95823b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "print(len(b1))\n",
        "print(len(b2))\n",
        "print(len(b3))\n",
        "print(len(b4))\n",
        "print(len(b51))\n",
        "print(len(b61))\n",
        "print(len(b71))\n",
        "print(len(b52))\n",
        "print(len(b62))\n",
        "print(len(b72))\n",
        "print(len(b53))\n",
        "print(len(b63))\n",
        "print(len(b73))\n",
        "print(len(b54))\n",
        "print(len(b64))\n",
        "print(len(b74))\n",
        "print(len(b55))\n",
        "print(len(b65))\n",
        "print(len(b75))\n",
        "print(len(b56))\n",
        "print(len(b66))\n",
        "print(len(b76))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "5\n",
            "5\n",
            "2\n",
            "5\n",
            "5\n",
            "2\n",
            "5\n",
            "5\n",
            "2\n",
            "5\n",
            "5\n",
            "2\n",
            "5\n",
            "5\n",
            "2\n",
            "5\n",
            "5\n",
            "2\n",
            "5\n",
            "5\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7BQH-3NYvrQ",
        "colab_type": "code",
        "outputId": "69505011-6397-469a-a60d-7fa7fae659d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "l = 0\n",
        "for i in b1:\n",
        "    print(\"%d Noise is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(noise[l])))\n",
        "    l= l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Noise is:\n",
            "2 Noise is:\n",
            "3 Noise is:\n",
            "4 Noise is:\n",
            "5 Noise is:\n",
            "6 Noise is:\n",
            "7 Noise is:\n",
            "8 Noise is:\n",
            "9 Noise is:\n",
            "10 Noise is:\n",
            "11 Noise is:\n",
            "12 Noise is:\n",
            "13 Noise is:\n",
            "14 Noise is:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7avpXBA0WT_N",
        "colab_type": "code",
        "outputId": "cc71eb92-ca45-4685-a8fb-7ea0b8049e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "l = 0\n",
        "for i in b2:\n",
        "    print(\"%d Noise is:\" %(l+1))\n",
        "    if(l==0):\n",
        "        print(sess.run(i[0][0][0][0]))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(const[l])))\n",
        "    if(l==0):\n",
        "        print(sess.run(i[0][0][0][0]))\n",
        "        print(const[l][0][0][0][0])\n",
        "    print(\" \")\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Noise is:\n",
            "1.0\n",
            "-1.84618\n",
            "-1.84618\n",
            " \n",
            "2 Noise is:\n",
            " \n",
            "3 Noise is:\n",
            " \n",
            "4 Noise is:\n",
            " \n",
            "5 Noise is:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9gKxyZUXIL7",
        "colab_type": "code",
        "outputId": "ad6c70ed-d09b-40a2-a9fa-49012cc24d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "l = 0\n",
        "for i in b3:\n",
        "    print(\"%d Initial Convolution Weights is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights1[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b4:\n",
        "    print(\"%d Initial Convolution Weights is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights1[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Initial Convolution Weights is:\n",
            " \n",
            "2 Initial Convolution Weights is:\n",
            " \n",
            "3 Initial Convolution Weights is:\n",
            " \n",
            "4 Initial Convolution Weights is:\n",
            " \n",
            "5 Initial Convolution Weights is:\n",
            " \n",
            "6 Initial Convolution Weights is:\n",
            " \n",
            "7 Initial Convolution Weights is:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjUs18PvTkIr",
        "colab_type": "code",
        "outputId": "d56e6d38-fcfb-4a04-baf9-55b3cbc61c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in b51:\n",
        "    print(\"%d Initial Convolution Weights 2 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights2[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b61:\n",
        "    print(\"%d Initial Convolution Weights 2 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights2[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b71:\n",
        "    print(\"%d Initial Convolution Weights 2 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights2[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Initial Convolution Weights 2 is:\n",
            " \n",
            "2 Initial Convolution Weights 2 is:\n",
            " \n",
            "3 Initial Convolution Weights 2 is:\n",
            " \n",
            "4 Initial Convolution Weights 2 is:\n",
            " \n",
            "5 Initial Convolution Weights 2 is:\n",
            " \n",
            "6 Initial Convolution Weights 2 is:\n",
            " \n",
            "7 Initial Convolution Weights 2 is:\n",
            " \n",
            "8 Initial Convolution Weights 2 is:\n",
            " \n",
            "9 Initial Convolution Weights 2 is:\n",
            " \n",
            "10 Initial Convolution Weights 2 is:\n",
            " \n",
            "11 Initial Convolution Weights 2 is:\n",
            " \n",
            "12 Initial Convolution Weights 2 is:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVlFAP5TsVJE",
        "colab_type": "code",
        "outputId": "aab81f1f-4b49-4ed2-8ee7-96fba680a43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in b52:\n",
        "    print(\"%d Initial Convolution Weights 3 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights3[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b62:\n",
        "    print(\"%d Initial Convolution Weights 3 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights3[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b72:\n",
        "    print(\"%d Initial Convolution Weights 3 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights3[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Initial Convolution Weights 3 is:\n",
            " \n",
            "2 Initial Convolution Weights 3 is:\n",
            " \n",
            "3 Initial Convolution Weights 3 is:\n",
            " \n",
            "4 Initial Convolution Weights 3 is:\n",
            " \n",
            "5 Initial Convolution Weights 3 is:\n",
            " \n",
            "6 Initial Convolution Weights 3 is:\n",
            " \n",
            "7 Initial Convolution Weights 3 is:\n",
            " \n",
            "8 Initial Convolution Weights 3 is:\n",
            " \n",
            "9 Initial Convolution Weights 3 is:\n",
            " \n",
            "10 Initial Convolution Weights 3 is:\n",
            " \n",
            "11 Initial Convolution Weights 3 is:\n",
            " \n",
            "12 Initial Convolution Weights 3 is:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTd-ktiOsbHq",
        "colab_type": "code",
        "outputId": "adf6965b-2c31-4e87-a091-de588121fa6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in b53:\n",
        "    print(\"%d Initial Convolution Weights 4 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights4[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b63:\n",
        "    print(\"%d Initial Convolution Weights 4 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights4[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b73:\n",
        "    print(\"%d Initial Convolution Weights 4 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights4[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Initial Convolution Weights 4 is:\n",
            " \n",
            "2 Initial Convolution Weights 4 is:\n",
            " \n",
            "3 Initial Convolution Weights 4 is:\n",
            " \n",
            "4 Initial Convolution Weights 4 is:\n",
            " \n",
            "5 Initial Convolution Weights 4 is:\n",
            " \n",
            "6 Initial Convolution Weights 4 is:\n",
            " \n",
            "7 Initial Convolution Weights 4 is:\n",
            " \n",
            "8 Initial Convolution Weights 4 is:\n",
            " \n",
            "9 Initial Convolution Weights 4 is:\n",
            " \n",
            "10 Initial Convolution Weights 4 is:\n",
            " \n",
            "11 Initial Convolution Weights 4 is:\n",
            " \n",
            "12 Initial Convolution Weights 4 is:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC61peZassaI",
        "colab_type": "code",
        "outputId": "283f906a-9750-456f-93ff-d162c6c02269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in b54:\n",
        "    print(\"%d Initial Convolution Weights 5 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights5[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b64:\n",
        "    print(\"%d Initial Convolution Weights 5 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights5[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b74:\n",
        "    print(\"%d Initial Convolution Weights 5 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights5[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Initial Convolution Weights 5 is:\n",
            " \n",
            "2 Initial Convolution Weights 5 is:\n",
            " \n",
            "3 Initial Convolution Weights 5 is:\n",
            " \n",
            "4 Initial Convolution Weights 5 is:\n",
            " \n",
            "5 Initial Convolution Weights 5 is:\n",
            " \n",
            "6 Initial Convolution Weights 5 is:\n",
            " \n",
            "7 Initial Convolution Weights 5 is:\n",
            " \n",
            "8 Initial Convolution Weights 5 is:\n",
            " \n",
            "9 Initial Convolution Weights 5 is:\n",
            " \n",
            "10 Initial Convolution Weights 5 is:\n",
            " \n",
            "11 Initial Convolution Weights 5 is:\n",
            " \n",
            "12 Initial Convolution Weights 5 is:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_0xC2O7szVT",
        "colab_type": "code",
        "outputId": "fdec8a0c-3e82-4541-cec6-2e2466d9d7b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in b55:\n",
        "    print(\"%d Initial Convolution Weights 6 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights6[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b65:\n",
        "    print(\"%d Initial Convolution Weights 6 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights6[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b75:\n",
        "    print(\"%d Initial Convolution Weights 6 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights6[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Initial Convolution Weights 6 is:\n",
            " \n",
            "2 Initial Convolution Weights 6 is:\n",
            " \n",
            "3 Initial Convolution Weights 6 is:\n",
            " \n",
            "4 Initial Convolution Weights 6 is:\n",
            " \n",
            "5 Initial Convolution Weights 6 is:\n",
            " \n",
            "6 Initial Convolution Weights 6 is:\n",
            " \n",
            "7 Initial Convolution Weights 6 is:\n",
            " \n",
            "8 Initial Convolution Weights 6 is:\n",
            " \n",
            "9 Initial Convolution Weights 6 is:\n",
            " \n",
            "10 Initial Convolution Weights 6 is:\n",
            " \n",
            "11 Initial Convolution Weights 6 is:\n",
            " \n",
            "12 Initial Convolution Weights 6 is:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55HpcB7Zs6DQ",
        "colab_type": "code",
        "outputId": "407261a9-41de-4540-9e94-561cb6814576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in b56:\n",
        "    print(\"%d Initial Convolution Weights 7 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights7[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b66:\n",
        "    print(\"%d Initial Convolution Weights 7 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights7[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1\n",
        "\n",
        "for i in b76:\n",
        "    print(\"%d Initial Convolution Weights 7 is:\" %(l+1))\n",
        "    sess.run(i.assign(tf.convert_to_tensor(initial_conv_weights7[l])))\n",
        "    print(\" \")\n",
        "    l= l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Initial Convolution Weights 7 is:\n",
            " \n",
            "2 Initial Convolution Weights 7 is:\n",
            " \n",
            "3 Initial Convolution Weights 7 is:\n",
            " \n",
            "4 Initial Convolution Weights 7 is:\n",
            " \n",
            "5 Initial Convolution Weights 7 is:\n",
            " \n",
            "6 Initial Convolution Weights 7 is:\n",
            " \n",
            "7 Initial Convolution Weights 7 is:\n",
            " \n",
            "8 Initial Convolution Weights 7 is:\n",
            " \n",
            "9 Initial Convolution Weights 7 is:\n",
            " \n",
            "10 Initial Convolution Weights 7 is:\n",
            " \n",
            "11 Initial Convolution Weights 7 is:\n",
            " \n",
            "12 Initial Convolution Weights 7 is:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt9ySPZcJBxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lis2, out2 = G_synthesis12(inputx, num_channels = 3, resolution= 256, randomize_noise = False, use_wscale = False, fused_scale=False, structure='linear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0NqFg_I2vZV",
        "colab_type": "code",
        "outputId": "6dc2fbdc-39ce-4bb4-b9d7-7abeb851171b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(sess.run(out2[0][0][0][0]))\n",
        "print(sess.run(out2[0][0][0][1]))\n",
        "print(sess.run(out2[0][0][0][2]))\n",
        "print(sess.run(out2[0][0][0][3]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.214869\n",
            "-12.609013\n",
            "-23.258228\n",
            "-49.759335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CoSyxRrLMn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezwu0ttvLMxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K0HURcW2vhw",
        "colab_type": "code",
        "outputId": "b23fb9e0-1525-40a8-b722-fa95e6019a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "l = 0\n",
        "for i in lis2[0]:\n",
        "  if(l>0):\n",
        "    print(\"%d Output is:\" %(l))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print()\n",
        "  else:\n",
        "    print(\"1St Input is:\")\n",
        "    print(sess.run(i[0][0][0]))\n",
        "    print(sess.run(i[0][0][1]))\n",
        "    print(sess.run(i[0][0][2]))\n",
        "    print()\n",
        "  l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1St Input is:\n",
            "0.83128\n",
            "0.2854586\n",
            "0.9196952\n",
            "\n",
            "1 Output is:\n",
            "-1.84618\n",
            "6.3599644\n",
            "0.12951864\n",
            "\n",
            "2 Output is:\n",
            "20270.738\n",
            "-104380.0\n",
            "-258549.94\n",
            "\n",
            "3 Output is:\n",
            "-65122.805\n",
            "-94974.875\n",
            "-38889.06\n",
            "\n",
            "4 Output is:\n",
            "-7454.548\n",
            "-33308.004\n",
            "-38218.707\n",
            "\n",
            "5 Output is:\n",
            "89440.445\n",
            "60078.76\n",
            "51687.977\n",
            "\n",
            "6 Output is:\n",
            "27369.43\n",
            "15288.547\n",
            "22480.377\n",
            "\n",
            "7 Output is:\n",
            "-8352.848\n",
            "-9601.129\n",
            "-8677.818\n",
            "\n",
            "8 Output is:\n",
            "-87.29541\n",
            "7417.2812\n",
            "6112.753\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4bom07j2ve_",
        "colab_type": "code",
        "outputId": "bc7b2d99-c5cd-4834-dd28-1506b815745b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "l = 0\n",
        "for i in lis2[1]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-86534.234\n",
            "-139699.39\n",
            "-147677.02\n",
            "-152247.47\n",
            "\n",
            "2 Output is:\n",
            "-81667.58\n",
            "-115441.414\n",
            "-106167.01\n",
            "-106196.555\n",
            "\n",
            "3 Output is:\n",
            "139967.61\n",
            "136911.22\n",
            "79867.53\n",
            "86454.64\n",
            "\n",
            "4 Output is:\n",
            "196072.95\n",
            "297424.25\n",
            "302385.38\n",
            "295122.44\n",
            "\n",
            "5 Output is:\n",
            "933.8535\n",
            "9375.004\n",
            "13146.991\n",
            "19079.512\n",
            "\n",
            "6 Output is:\n",
            "-9602.999\n",
            "-4809.956\n",
            "-8587.126\n",
            "-20599.746\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P3If_n92vcZ",
        "colab_type": "code",
        "outputId": "5945abe8-b5bd-496a-837e-3d85014711a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "l = 0\n",
        "for i in lis2[2]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-47362.38\n",
            "-77966.36\n",
            "-93147.164\n",
            "-101218.66\n",
            "\n",
            "2 Output is:\n",
            "-58360.664\n",
            "-88165.27\n",
            "-92632.87\n",
            "-89882.06\n",
            "\n",
            "3 Output is:\n",
            "84949.38\n",
            "100646.77\n",
            "74192.13\n",
            "61205.906\n",
            "\n",
            "4 Output is:\n",
            "151131.81\n",
            "236022.22\n",
            "247845.23\n",
            "208118.33\n",
            "\n",
            "5 Output is:\n",
            "2486.7075\n",
            "6073.914\n",
            "7059.1035\n",
            "4319.425\n",
            "\n",
            "6 Output is:\n",
            "-882.70386\n",
            "660.4984\n",
            "-1894.5182\n",
            "-8439.295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0XqaHpM4M5s",
        "colab_type": "code",
        "outputId": "e2c38970-d885-4a46-dea2-6f6167fdd2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "l = 0\n",
        "for i in lis2[3]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-2.0104156\n",
            "6.4205313\n",
            "0.12872617\n",
            "-7.7757373\n",
            "\n",
            "2 Output is:\n",
            "20269.348\n",
            "-104383.76\n",
            "-258550.44\n",
            "-126136.34\n",
            "\n",
            "3 Output is:\n",
            "-47362.94\n",
            "-77965.73\n",
            "-93149.016\n",
            "-101218.914\n",
            "\n",
            "4 Output is:\n",
            "-65122.85\n",
            "-94974.91\n",
            "-38889.05\n",
            "18012.846\n",
            "\n",
            "5 Output is:\n",
            "-58360.707\n",
            "-88165.01\n",
            "-92632.46\n",
            "-89882.445\n",
            "\n",
            "6 Output is:\n",
            "-7455.2754\n",
            "-33308.39\n",
            "-38218.047\n",
            "-38343.99\n",
            "\n",
            "7 Output is:\n",
            "84949.734\n",
            "100647.016\n",
            "74197.164\n",
            "61209.61\n",
            "\n",
            "8 Output is:\n",
            "89439.76\n",
            "60077.12\n",
            "51687.305\n",
            "40187.387\n",
            "\n",
            "9 Output is:\n",
            "151131.06\n",
            "236021.9\n",
            "247845.4\n",
            "208116.77\n",
            "\n",
            "10 Output is:\n",
            "27369.521\n",
            "15288.609\n",
            "22480.375\n",
            "30243.58\n",
            "\n",
            "11 Output is:\n",
            "2486.7183\n",
            "6073.941\n",
            "7059.193\n",
            "4319.41\n",
            "\n",
            "12 Output is:\n",
            "-8352.838\n",
            "-9601.122\n",
            "-8677.796\n",
            "-10648.09\n",
            "\n",
            "13 Output is:\n",
            "-883.53485\n",
            "657.83673\n",
            "-1892.0635\n",
            "-8441.823\n",
            "\n",
            "14 Output is:\n",
            "-87.298645\n",
            "7417.4097\n",
            "6112.742\n",
            "5586.7993\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rteGoeHg4M-q",
        "colab_type": "code",
        "outputId": "ba098e30-67e6-446f-edf9-010683990172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "l = 0\n",
        "for i in lis2[4]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-0.77507746\n",
            "7.6558695\n",
            "1.3640642\n",
            "-6.540399\n",
            "\n",
            "2 Output is:\n",
            "20269.697\n",
            "-104383.41\n",
            "-258550.1\n",
            "-126135.99\n",
            "\n",
            "3 Output is:\n",
            "-47360.027\n",
            "-77962.81\n",
            "-93146.1\n",
            "-101216.0\n",
            "\n",
            "4 Output is:\n",
            "-65122.117\n",
            "-94974.17\n",
            "-38888.316\n",
            "18013.578\n",
            "\n",
            "5 Output is:\n",
            "-58355.426\n",
            "-88159.73\n",
            "-92627.18\n",
            "-89877.164\n",
            "\n",
            "6 Output is:\n",
            "-7452.5596\n",
            "-33305.676\n",
            "-38215.332\n",
            "-38341.273\n",
            "\n",
            "7 Output is:\n",
            "84959.84\n",
            "100657.125\n",
            "74207.27\n",
            "61219.715\n",
            "\n",
            "8 Output is:\n",
            "89438.0\n",
            "60075.363\n",
            "51685.547\n",
            "40185.63\n",
            "\n",
            "9 Output is:\n",
            "151126.75\n",
            "236017.6\n",
            "247841.1\n",
            "208112.45\n",
            "\n",
            "10 Output is:\n",
            "27365.73\n",
            "15284.818\n",
            "22476.584\n",
            "30239.79\n",
            "\n",
            "11 Output is:\n",
            "2486.5928\n",
            "6073.8154\n",
            "7059.0674\n",
            "4319.2847\n",
            "\n",
            "12 Output is:\n",
            "-8352.869\n",
            "-9601.153\n",
            "-8677.827\n",
            "-10648.121\n",
            "\n",
            "13 Output is:\n",
            "-862.9659\n",
            "678.4057\n",
            "-1871.4945\n",
            "-8421.254\n",
            "\n",
            "14 Output is:\n",
            "-86.26122\n",
            "7418.4473\n",
            "6113.78\n",
            "5587.837\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-EoZHrT4NCH",
        "colab_type": "code",
        "outputId": "2668bc55-3720-461b-cfef-13efe00de446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "l = 0\n",
        "for i in lis2[5]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-0.1550155\n",
            "7.6558695\n",
            "1.3640642\n",
            "-1.3080798\n",
            "\n",
            "2 Output is:\n",
            "20269.697\n",
            "-20876.682\n",
            "-51710.02\n",
            "-25227.2\n",
            "\n",
            "3 Output is:\n",
            "-9472.006\n",
            "-15592.5625\n",
            "-18629.22\n",
            "-20243.201\n",
            "\n",
            "4 Output is:\n",
            "-13024.424\n",
            "-18994.834\n",
            "-7777.6636\n",
            "18013.578\n",
            "\n",
            "5 Output is:\n",
            "-11671.085\n",
            "-17631.945\n",
            "-18525.436\n",
            "-17975.434\n",
            "\n",
            "6 Output is:\n",
            "-1490.512\n",
            "-6661.1353\n",
            "-7643.0664\n",
            "-7668.255\n",
            "\n",
            "7 Output is:\n",
            "84959.84\n",
            "100657.125\n",
            "74207.27\n",
            "61219.715\n",
            "\n",
            "8 Output is:\n",
            "89438.0\n",
            "60075.363\n",
            "51685.547\n",
            "40185.63\n",
            "\n",
            "9 Output is:\n",
            "151126.75\n",
            "236017.6\n",
            "247841.1\n",
            "208112.45\n",
            "\n",
            "10 Output is:\n",
            "27365.73\n",
            "15284.818\n",
            "22476.584\n",
            "30239.79\n",
            "\n",
            "11 Output is:\n",
            "2486.5928\n",
            "6073.8154\n",
            "7059.0674\n",
            "4319.2847\n",
            "\n",
            "12 Output is:\n",
            "-1670.5739\n",
            "-1920.2307\n",
            "-1735.5654\n",
            "-2129.6243\n",
            "\n",
            "13 Output is:\n",
            "-172.59319\n",
            "678.4057\n",
            "-374.29892\n",
            "-1684.2509\n",
            "\n",
            "14 Output is:\n",
            "-17.252245\n",
            "7418.4473\n",
            "6113.78\n",
            "5587.837\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1ytCUu_4hpq",
        "colab_type": "code",
        "outputId": "94c6d025-207d-45b2-9537-f7ee3a319694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "l = 0\n",
        "for i in lis2[6]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-1.0466243\n",
            "1.964768\n",
            "-0.46096146\n",
            "-1.4911743\n",
            "\n",
            "2 Output is:\n",
            "1.3550243\n",
            "-0.5365803\n",
            "-1.954068\n",
            "-0.7365848\n",
            "\n",
            "3 Output is:\n",
            "1.3220385\n",
            "0.24045923\n",
            "-0.29615647\n",
            "-0.58136714\n",
            "\n",
            "4 Output is:\n",
            "-1.67347\n",
            "-1.7337677\n",
            "-1.6204807\n",
            "-1.3600038\n",
            "\n",
            "5 Output is:\n",
            "1.0940474\n",
            "0.088608876\n",
            "-0.06209915\n",
            "0.030671543\n",
            "\n",
            "6 Output is:\n",
            "-1.0768757\n",
            "-1.1827168\n",
            "-1.2028167\n",
            "-1.2033323\n",
            "\n",
            "7 Output is:\n",
            "0.21005447\n",
            "0.4979605\n",
            "0.0128400875\n",
            "-0.22536653\n",
            "\n",
            "8 Output is:\n",
            "0.8832909\n",
            "0.43437082\n",
            "0.3061004\n",
            "0.13028023\n",
            "\n",
            "9 Output is:\n",
            "0.88094425\n",
            "1.5024749\n",
            "1.589041\n",
            "1.2981666\n",
            "\n",
            "10 Output is:\n",
            "0.8407654\n",
            "0.35147288\n",
            "0.64274865\n",
            "0.9571685\n",
            "\n",
            "11 Output is:\n",
            "0.0033882388\n",
            "0.3352857\n",
            "0.42644334\n",
            "0.17295279\n",
            "\n",
            "12 Output is:\n",
            "-0.36160192\n",
            "-0.46604714\n",
            "-0.38879147\n",
            "-0.553648\n",
            "\n",
            "13 Output is:\n",
            "-1.2150289\n",
            "-1.1634358\n",
            "-1.2272575\n",
            "-1.3066751\n",
            "\n",
            "14 Output is:\n",
            "-0.032780968\n",
            "1.1353562\n",
            "0.93039495\n",
            "0.8477701\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_pd7odN4sRD",
        "colab_type": "code",
        "outputId": "b924c575-7628-401a-c058-5c07a00493c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "l = 0\n",
        "for i in lis2[7]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "7.758049\n",
            "-216.90973\n",
            "-35.93588\n",
            "40.924126\n",
            "\n",
            "2 Output is:\n",
            "-136.65549\n",
            "-65.117355\n",
            "-11.50975\n",
            "-57.553444\n",
            "\n",
            "3 Output is:\n",
            "-131.7185\n",
            "-74.15669\n",
            "-45.59793\n",
            "-30.41898\n",
            "\n",
            "4 Output is:\n",
            "419.69623\n",
            "438.08603\n",
            "403.53537\n",
            "324.0942\n",
            "\n",
            "5 Output is:\n",
            "37.34501\n",
            "12.958047\n",
            "9.302616\n",
            "11.552774\n",
            "\n",
            "6 Output is:\n",
            "-75.569115\n",
            "-79.91198\n",
            "-80.73672\n",
            "-80.75787\n",
            "\n",
            "7 Output is:\n",
            "-93.56799\n",
            "-147.77458\n",
            "-56.436707\n",
            "-11.587456\n",
            "\n",
            "8 Output is:\n",
            "99.10971\n",
            "83.77889\n",
            "79.39841\n",
            "73.39407\n",
            "\n",
            "9 Output is:\n",
            "329.2097\n",
            "518.44196\n",
            "544.79803\n",
            "456.2379\n",
            "\n",
            "10 Output is:\n",
            "-141.64433\n",
            "-117.61006\n",
            "-131.91766\n",
            "-147.3621\n",
            "\n",
            "11 Output is:\n",
            "-14.405905\n",
            "-101.68496\n",
            "-125.65668\n",
            "-58.996284\n",
            "\n",
            "12 Output is:\n",
            "19.815739\n",
            "8.009159\n",
            "16.74221\n",
            "-1.8933144\n",
            "\n",
            "13 Output is:\n",
            "62.318832\n",
            "63.591736\n",
            "62.017124\n",
            "60.057728\n",
            "\n",
            "14 Output is:\n",
            "-19.65595\n",
            "57.700832\n",
            "44.127815\n",
            "38.656204\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4qOot-34sXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA6Qh_el4htR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIx-zAQ_JB6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfKO8lr0XcPl",
        "colab_type": "code",
        "outputId": "b880536f-3da6-4900-afda-47611fdbeb0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "list2, output2 = G1(input, use_style = True, use_noise = False, randomize_noise=False, use_wscale = False, structure = 'linear')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6b73f84c7787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_style\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomize_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_wscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'G1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkQKHcFHGY41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8GJklgdGY75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "o2 = G_synthesis(inputx, num_channels = 3, resolution= 256, randomize_noise = False, use_wscale = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-0w8faUJGdf",
        "colab_type": "code",
        "outputId": "1baa0a0d-d1eb-47c0-ac87-7a2dc24c8363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(sess.run(o2[0][0][0][0]))\n",
        "print(sess.run(o2[0][0][0][1]))\n",
        "print(sess.run(o2[0][0][0][2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-59.79628\n",
            "-103.082016\n",
            "-116.63952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbbiQHbeJGgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuVSpoaIGZH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9MOWCKcw0eg",
        "colab_type": "code",
        "outputId": "b7ec3c7b-f40f-47d3-f3ec-5b9eda174eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(sess.run(output2[0][0][0][0]))\n",
        "print(sess.run(output2[0][0][0][1]))\n",
        "print(sess.run(output2[0][0][0][2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.85311663\n",
            "0.9419849\n",
            "1.038805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbvM4dYXxepB",
        "colab_type": "code",
        "outputId": "32349b27-d7ea-4b57-89c5-72478e88e75f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(input1[0][0][0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8312799770878936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lMUZbEXXnc3",
        "colab_type": "code",
        "outputId": "331aa926-d0ed-475d-db9b-72ab4763be72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "l = 0\n",
        "for i in list2[0]:\n",
        "  if(l>0):\n",
        "    print(\"%d Output is:\" %(l))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print()\n",
        "  else:\n",
        "    print(\"1St Input is:\")\n",
        "    print(sess.run(i[0][0][0]))\n",
        "    print(sess.run(i[0][0][1]))\n",
        "    print(sess.run(i[0][0][2]))\n",
        "    print()\n",
        "  l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1St Input is:\n",
            "0.83128\n",
            "0.2854586\n",
            "0.9196952\n",
            "\n",
            "1 Output is:\n",
            "-1.84618\n",
            "6.3599644\n",
            "0.12951864\n",
            "\n",
            "2 Output is:\n",
            "-12010.066\n",
            "-31704.414\n",
            "-41272.45\n",
            "\n",
            "3 Output is:\n",
            "-15597.707\n",
            "-40521.11\n",
            "6768.142\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4omJSivwzbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjAIn-afYFmY",
        "colab_type": "code",
        "outputId": "020e6dad-914a-4494-bbf1-c6cac218aba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in list2[1]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-2.0104156\n",
            "6.4205313\n",
            "0.12872617\n",
            "-7.7757373\n",
            "\n",
            "2 Output is:\n",
            "20269.348\n",
            "-104383.76\n",
            "-258550.44\n",
            "-126136.34\n",
            "\n",
            "3 Output is:\n",
            "-12010.63\n",
            "-31703.781\n",
            "-41274.305\n",
            "-35035.707\n",
            "\n",
            "4 Output is:\n",
            "-15597.755\n",
            "-40521.14\n",
            "6768.1494\n",
            "52193.504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8MyOJJ6Y_ne",
        "colab_type": "code",
        "outputId": "3746dc5f-eb33-4eb3-c0b7-3303337f7ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in list2[2]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-0.77507746\n",
            "7.6558695\n",
            "1.3640642\n",
            "-6.540399\n",
            "\n",
            "2 Output is:\n",
            "20269.697\n",
            "-104383.41\n",
            "-258550.1\n",
            "-126135.99\n",
            "\n",
            "3 Output is:\n",
            "-12007.716\n",
            "-31700.867\n",
            "-41271.39\n",
            "-35032.793\n",
            "\n",
            "4 Output is:\n",
            "-15597.022\n",
            "-40520.406\n",
            "6768.8823\n",
            "52194.24\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9RfKgVkZBG_",
        "colab_type": "code",
        "outputId": "11eaa765-6b87-4761-eabf-c2791445cdd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in list2[3]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-0.1550155\n",
            "7.6558695\n",
            "1.3640642\n",
            "-1.3080798\n",
            "\n",
            "2 Output is:\n",
            "20269.697\n",
            "-20876.682\n",
            "-51710.02\n",
            "-25227.2\n",
            "\n",
            "3 Output is:\n",
            "-2401.5432\n",
            "-6340.1733\n",
            "-8254.278\n",
            "-7006.5586\n",
            "\n",
            "4 Output is:\n",
            "-3119.4045\n",
            "-8104.0815\n",
            "6768.8823\n",
            "52194.24\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srvmDqgpZCam",
        "colab_type": "code",
        "outputId": "b8a18b25-534a-4b0c-a90f-fb74dfa00fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in list2[4]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-1.0466243\n",
            "1.964768\n",
            "-0.46096146\n",
            "-1.4911743\n",
            "\n",
            "2 Output is:\n",
            "1.3550243\n",
            "-0.5365803\n",
            "-1.954068\n",
            "-0.7365848\n",
            "\n",
            "3 Output is:\n",
            "2.4080899\n",
            "1.7835858\n",
            "1.4800879\n",
            "1.6779248\n",
            "\n",
            "4 Output is:\n",
            "-1.8152492\n",
            "-1.8745228\n",
            "-1.6976659\n",
            "-1.1575049\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxMe6MaPZD5w",
        "colab_type": "code",
        "outputId": "d8b35ad6-c592-495b-8675-438d8738d0d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "l = 0\n",
        "for i in list2[5]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "7.758049\n",
            "-216.90973\n",
            "-35.93588\n",
            "40.924126\n",
            "\n",
            "2 Output is:\n",
            "-136.65549\n",
            "-65.117355\n",
            "-11.50975\n",
            "-57.553444\n",
            "\n",
            "3 Output is:\n",
            "-189.51831\n",
            "-156.2821\n",
            "-140.12991\n",
            "-150.65881\n",
            "\n",
            "4 Output is:\n",
            "462.93655\n",
            "481.014\n",
            "427.0756\n",
            "262.33536\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH3jQ-uUZFQu",
        "colab_type": "code",
        "outputId": "a886b946-3777-47c4-f418-ea6d8056a09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "l = 0\n",
        "for i in list2[6]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-8141.2607\n",
            "-2891.1162\n",
            "-1466.6011\n",
            "-1448.821\n",
            "\n",
            "2 Output is:\n",
            "907.33386\n",
            "3396.8694\n",
            "3403.1763\n",
            "3161.273\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYWA3b3rcjFW",
        "colab_type": "code",
        "outputId": "6695f06d-0ea4-4773-99d6-8bb5f63fd97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "l = 0\n",
        "for i in list2[7]:\n",
        "    print(\"%d Output is:\" %(l+1))\n",
        "    print(sess.run(i[0][0][0][0]))\n",
        "    print(sess.run(i[0][0][0][1]))\n",
        "    print(sess.run(i[0][0][0][2]))\n",
        "    print(sess.run(i[0][0][0][3]))\n",
        "    print()\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Output is:\n",
            "-8141.2607\n",
            "-2891.1162\n",
            "-1466.6011\n",
            "-1448.821\n",
            "\n",
            "2 Output is:\n",
            "907.33386\n",
            "3396.8694\n",
            "3403.1763\n",
            "3161.273\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxeD0BdDbSmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}