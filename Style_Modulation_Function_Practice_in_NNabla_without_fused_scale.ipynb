{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Style Modulation Function Practice in NNabla without fused_scale.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPF8K4srNqSHmuOq6VcFGhU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJNahata/Style-GANS-Practice/blob/master/Style_Modulation_Function_Practice_in_NNabla_without_fused_scale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df1GSUkWptnF",
        "colab_type": "code",
        "outputId": "f5744d8d-22a4-4db1-fbb3-9575346d8f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "!pip install nnabla"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nnabla\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/29/e2a05e0c9f0f9f3647fcd4a04bc167bb8bf85d8246581951f0dd3c206457/nnabla-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2MB 243kB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from nnabla) (2.4.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from nnabla) (1.12.40)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from nnabla) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from nnabla) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nnabla) (1.12.0)\n",
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/f4/e126b60d109ad1e80020071484b935980b7cce1e4796073aab086a2d6902/onnx-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (4.8MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from nnabla) (2.21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nnabla) (1.4.1)\n",
            "Collecting configparser\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nnabla) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.6 in /usr/local/lib/python3.6/dist-packages (from nnabla) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nnabla) (4.38.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from nnabla) (2.10.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from nnabla) (0.5.5)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from nnabla) (0.29.16)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from nnabla) (46.1.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->nnabla) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->nnabla) (1.15.40)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->nnabla) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->nnabla) (3.6.6)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->nnabla) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->nnabla) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->nnabla) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->nnabla) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->nnabla) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->nnabla) (2.8.1)\n",
            "Installing collected packages: onnx, configparser, nnabla\n",
            "Successfully installed configparser-5.0.0 nnabla-1.7.0 onnx-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nejCN6GPnlbD",
        "colab_type": "code",
        "outputId": "0ee4c93d-5232-4486-f8ca-00a1d37b6942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import numpy as np\n",
        "import nnabla as nn\n",
        "import nnabla.parametric_functions as PF\n",
        "import nnabla.functions as F\n",
        "import nnabla.solvers as S\n",
        "import nnabla.logger as logger\n",
        "import nnabla.utils.save as save\n",
        "from nnabla.parameter import get_parameter_or_create\n",
        "from nnabla.ext_utils import get_extension_context\n",
        "from nnabla.parametric_functions import parametric_function_api\n",
        "import nnabla.initializer as I\n",
        "nn.set_auto_forward(True)\n",
        "print(\"DJ1\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-21 18:36:21,314 [nnabla][INFO]: Initializing CPU extension...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DJ1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCv7Rdpd5EFc",
        "colab_type": "code",
        "outputId": "c22a4735-5ce2-40b3-e02a-30336dbcbe48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "from __future__ import absolute_import\n",
        "from six.moves import range\n",
        "print(\"DJ1\")\n",
        "\n",
        "import functools\n",
        "# Globally prepared params.\n",
        "w = nn.parameter.get_parameter_or_create('BLURRING_FILTER', shape=(3,3), need_grad=False)  #why and how is it used for the parameter\n",
        "w.d = np.array([[1., 2., 1.], [2., 4., 2.], [1., 2., 1.]])   \n",
        "\n",
        "print('')\n",
        "\n",
        "\n",
        "def lerp(a, b, t):\n",
        "  print(\"Value of t is\", t)\n",
        "  if(t>0):\n",
        "    return ((a + (b - a) * t))\n",
        "  else:\n",
        "    print(\"Only a\")\n",
        "    return a\n",
        "\n",
        "def lerp_clip(a, b, t):\n",
        "    return (a + (b - a) * F.clip_by_value(t, 0.0, 1.0))\n",
        "\n",
        "\n",
        "#Computing the mean across the feature maps i.e. axis 2 and 3 for H and W with data format of x as NCHW\n",
        "#--------------------\n",
        "def compute_channel_mean(x, keepdims = True):\n",
        "    ch_mean = F.mean(x, axis = [2,3], keepdims = keepdims)\n",
        "    return ch_mean\n",
        "\n",
        "#--------------------\n",
        "\n",
        "\n",
        "#-------------------------------\n",
        "#Computing the standard deviation across the feature maps i.e. axis 2 and 3 for H and W with data format of x as NCHW\n",
        "def compute_channel_std(x, keepdims = True):\n",
        "    x1 = compute_channel_mean(x)\n",
        "    var = F.mean(F.pow_scalar((x - x1), 2.0), axis = [2,3], keepdims = keepdims)\n",
        "    std = F.pow_scalar(var, 0.5)\n",
        "    return std\n",
        "\n",
        "#-------------------------------\n",
        "\n",
        "\n",
        "#---------------------------------------------------\n",
        "#Adaptive Instance Normalization to be used\n",
        "def adain(x, y):\n",
        "    y_s, y_b = y\n",
        "    ch1_mean = compute_channel_mean(x)\n",
        "    ch1_std = compute_channel_std(x)\n",
        "    x = (x - ch1_mean) / ch1_std\n",
        "    a1 = (y_s * x) + y_b\n",
        "    return a1 \n",
        "\n",
        "#-------------------------------\n",
        "\n",
        "\n",
        "#New blur function to be used ------------------------------------------\n",
        "def blur2d(x, f=[1,2,1], normalize = True, flip = False, stride = 1):\n",
        "    ## assert x.ndim == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(stride, int) and stride >= 1\n",
        "\n",
        "    f = np.array(f, dtype = np.float32)\n",
        "\n",
        "    if f.ndim == 1:\n",
        "        f = f[:, np.newaxis] * f[np.newaxis, :]\n",
        "\n",
        "    if flip:\n",
        "        f = f[::-1, ::-1]\n",
        "\n",
        "    if normalize:\n",
        "        f = f / np.sum(f)\n",
        "\n",
        "    f = f[ np.newaxis, :, :]\n",
        "    f = np.tile(f, [int(x.shape[1]), 1, 1])\n",
        "    if f.shape == (1, 1) and f[0,0] == 1:\n",
        "        return x\n",
        "\n",
        "    #orig_dtype = x.dtype\n",
        "    strides = (stride, stride) \n",
        "    w = nn.Variable.from_numpy_array(f)\n",
        "    padding = (w.shape[1] // 2, w.shape[2] // 2)\n",
        "\n",
        "    y = F.depthwise_convolution(x, w, pad = padding, stride = strides)\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DJ1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjwSRbXhAwpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weight(he_std, gain = np.sqrt(2), use_wscale = False, lrmul = 1):\n",
        "    if use_wscale:\n",
        "        init_std = 1.0 / lrmul\n",
        "        runtime_coeff = he_std * lrmul\n",
        "    else: \n",
        "        init_std = he_std / lrmul\n",
        "        runtime_coeff = lrmul\n",
        "\n",
        "    w_init = I.NormalInitializer(sigma = init_std)   #I.NormalInitializer function is used with sigma argument as the standard deviation, so as to get the weights of these variables \n",
        "    return w_init, runtime_coeff"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZFq_VFSAzMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downscale2d(x, factor = 2, gain = 1):\n",
        "    #assert x.ndim == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(factor, int) and factor >=1\n",
        "\n",
        "    if factor == 2:\n",
        "        f = [np.sqrt(gain) / factor] * factor\n",
        "        f = np.array(f, dtype = np.float32)\n",
        "        if f.ndim == 1:\n",
        "            f = f[:, np.newaxis] * f[np.newaxis, :]\n",
        "        assert f.ndim == 2\n",
        "\n",
        "        f = f[np.newaxis, :, :]\n",
        "        f = np.tile(f, [int(x.shape[1]), 1, 1])\n",
        "        w = nn.Variable.from_numpy_array(f)\n",
        "        strides = (factor, factor)\n",
        "        padding = (w.shape[1] // 2, w.shape[2] // 2)\n",
        "        \n",
        "        y = F.depthwise_convolution(x, w, stride = strides)\n",
        "        return y \n",
        "    \n",
        "    if gain != 1:\n",
        "        x = x * gain\n",
        "\n",
        "    if factor == 1:\n",
        "        return x\n",
        "\n",
        "    kernel = [factor, factor]\n",
        "    y = F.average_pooling(x, kernel = kernel, stride = kernel)    # a bit of doubt regarding this statement\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbEMx-NPA1Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dense(x, fmaps, gain = np.sqrt(2), use_wscale = False, lrmul = 1, **kwargs):\n",
        "    he_std = I.calc_normal_std_he_forward(x.shape[1], fmaps)\n",
        "    w_init, runtime_coeff = get_weight(he_std, gain, use_wscale, lrmul, **kwargs)\n",
        "    w = nn.parameter.get_parameter_or_create('Dense', shape = (x.shape[1], fmaps), initializer = w_init, need_grad = True)\n",
        "    w = w * runtime_coeff\n",
        "    return (F.affine(x, w, bias=None, base_axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VffG4XoAA3X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Upscale operation function to be used \n",
        "def upscale2d(x, factor = 2, gain = 1):\n",
        "    # to check whether the shape of the x is 4 or not\n",
        "    #assert x.ndim == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(factor, int) and factor >=1 \n",
        "\n",
        "    if gain!=1:\n",
        "        x = x * gain\n",
        "    \n",
        "    if factor == 1:\n",
        "        return x\n",
        "\n",
        "    s = x.shape\n",
        "    #reshape and tile function similar as that of the tensorflow\n",
        "    x = F.reshape(x, [-1, s[1], s[2], 1, s[3], 1], False)\n",
        "    x = F.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "    x = F.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBtJVHVyA5qF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x, fmaps, kernel, gain = np.sqrt(2), use_wscale = False, **kwargs):\n",
        "  with nn.parameter_scope('Convolution'):\n",
        "    assert isinstance(kernel, int) or isinstance(kernel, float)\n",
        "    assert kernel >= 1 and kernel % 2 == 1\n",
        "    if kernel == 1:\n",
        "        padding = None\n",
        "    else:\n",
        "        padding = ((kernel - 2), (kernel - 2))  #tuple of padding\n",
        "    kernel_tuple = (kernel, kernel)  #tuple of kernel_tuple\n",
        "    he_std = I.calc_normal_std_he_forward(fmaps, x.shape[1], kernel_tuple)        # (kernel, kernel, x.shape[1], fmaps) (3, 2, 0, 1)\n",
        "    w_init, runtime_coeff = get_weight(he_std, gain, use_wscale, **kwargs)\n",
        "    return PF.convolution(x, fmaps, kernel = kernel_tuple, w_init = w_init, with_bias = False, pad = padding, apply_w = lambda w: w * runtime_coeff)\n",
        "\n",
        "\n",
        "#usage of the Noise application which is used in the synthesis network.\n",
        "def apply_noise(x, noise_var = None, randomize_noise = True):\n",
        "    assert len(x.shape) == 4\n",
        "    with nn.parameter_scope('Noise'):\n",
        "        if noise_var is None or randomize_noise:\n",
        "            noise = F.randn(shape = (x.shape[0], 1, x.shape[2], x.shape[3]))\n",
        "        else:\n",
        "            print(\"Dj1\")\n",
        "            noise = noise_var\n",
        "        weight = nn.parameter.get_parameter_or_create(name = 'weight', shape = [x.shape[1]], initializer=I.ConstantInitializer(0))     # For Creating Random nnabla variable such that each entry follows the Normal Distribution..\n",
        "        weight = F.reshape(weight, [1, -1, 1, 1], inplace= False)\n",
        "        return (x + noise * weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtWMJhvtA9Ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upscale2d_conv2d(x, fmaps, kernel, gain = np.sqrt(2), use_wscale = False, fused_scale = 'auto', **kwargs):\n",
        "    assert kernel >= 1 and kernel % 2 == 1\n",
        "    assert fused_scale in [True, False, 'auto']\n",
        "    if fused_scale == 'auto':\n",
        "        fused_scale = min(x.shape[2:]) * 2 >= 128\n",
        "\n",
        "    if not fused_scale:\n",
        "        return conv2d(upscale2d(x), fmaps, kernel, **kwargs)\n",
        "\n",
        "    kernel_tuple = (kernel, kernel)\n",
        "    he_std = I.calc_normal_std_he_forward(x.shape[1], fmaps, kernel_tuple)        # (kernel, kernel, x.shape[1], fmaps)  (2, 3, 0, 1)\n",
        "    w_init, runtime_coeff = get_weight(he_std, gain, use_wscale, **kwargs)\n",
        "    w = nn.parameter.get_parameter_or_create('deconv/W', shape = (x.shape[1], fmaps, kernel, kernel), initializer = w_init, need_grad = True)\n",
        "    w = w * runtime_coeff\n",
        "    w = F.pad(w, (1, 1, 1, 1), mode = 'constant')\n",
        "    w = w[..., 1:, 1:] + w[..., :-1, 1:] + w[..., 1:, :-1] + w[..., :-1, :-1]\n",
        "    kernel_size = w.shape[-1]\n",
        "    padding = ((kernel_size - 2) / 2, (kernel_size - 2) / 2)\n",
        "    stride = (2 , 2)\n",
        "    return F.deconvolution(x, w, bias = None, pad = padding, stride = stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW8pt-HgA_wV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change in the apply_bias function.\n",
        "def apply_bias(x, lrmul = 1):\n",
        "    b = nn.parameter.get_parameter_or_create(name = 'bias', shape = [x.shape[1]], initializer = I.ConstantInitializer(0))   # Change the initializer to either float or convert the datatype to float32.\n",
        "    b = b * lrmul  # No Modifications requried..\n",
        "    if x.ndim == 2:\n",
        "        return (x + F.reshape(b, [1, -1]))\n",
        "    return (x + F.reshape(b, [1, -1, 1, 1])) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE1u7MzaBB-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the style modulation i.e. combining ys and yb with the resultant of the addition of the noise and the feature maps\n",
        "def style_mod(x, dlatent, **kwargs):\n",
        "    with nn.parameter_scope('StyleMod'):\n",
        "        style = apply_bias(dense(dlatent, fmaps = x.shape[1] * 2, **kwargs))\n",
        "        style = F.reshape(style, [-1, 2, x.shape[1]] + [1] * (len(x.shape) - 2))\n",
        "        return x * (style[:,0] + 1) + style[:,1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kis1m10IBIlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d_downscale2d(x, fmaps, kernel, gain = np.sqrt(2), use_wscale = False, fused_scale = 'auto', **kwargs):\n",
        "    #assert kernel % 2 == 1 and kernel >= 1\n",
        "    assert fused_scale in [True, False, 'auto']\n",
        "    if fused_scale == 'auto':\n",
        "        fused_scale = min(x.shape[2:]) >= 128   #why is this written and what is the condition behind that\n",
        "\n",
        "    if not fused_scale:\n",
        "        return downscale2d(conv2d(x, fmaps, kernel, **kwargs))\n",
        "\n",
        "    kernel_tuple = (kernel, kernel)\n",
        "    he_std = I.calc_normal_std_he_forward(fmaps, x.shape[1], kernel_tuple)       # (kernel, kernel, x.shape[1], fmaps) (3, 2, 0, 1)\n",
        "    w_init, runtime_coeff = get_weight(he_std, gain = gain, use_wscale = use_wscale, **kwargs)\n",
        "    w = nn.parameter.get_parameter_or_create('conv/W', shape = (fmaps, x.shape[1], kernel, kernel), initializer = w_init, need_grad = True)\n",
        "    w = w * runtime_coeff\n",
        "    w = F.pad(w, (1, 1, 1, 1), mode = 'constant')\n",
        "    w = w[..., 1:, 1:] + w[..., :-1, 1:] + w[..., 1:, :-1] + w[..., :-1, :-1]\n",
        "    w = w * 0.25\n",
        "    kernel_size = w.shape[-1]\n",
        "    padding = ((kernel_size - 2) / 2, (kernel_size - 2) / 2)\n",
        "    stride = (2,2)\n",
        "    return F.convolution(x, w, bias=None, pad = padding, stride = stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCP_oEguBKgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def minibatch_stddev_layer(x, group_size=4, num_new_features=1):\n",
        "    group_size = min(group_size, x.shape[0])     # Minibatch must be divisible by (or smaller than) group_size.\n",
        "    s = x.shape                                             # [NCHW]  Input shape.\n",
        "    y = F.reshape(x, [group_size, -1, num_new_features, s[1]//num_new_features, s[2], s[3]])   # [GMncHW] Split minibatch into M groups of size G. Split channels into n channel groups c.\n",
        "    y -= F.mean(y, axis=0, keepdims=True)           # [GMncHW] Subtract mean over group.\n",
        "    y = F.mean(F.pow_scalar(y, 2.0), axis=0)                # [MncHW]  Calc variance over group.\n",
        "    y = F.add_scalar(F.pow_scalar(y, 2.0) + 1e-8)                                   # [MncHW]  Calc stddev over group.\n",
        "    y = F.mean(y, axis=[2,3,4], keepdims=True)      # [Mn111]  Take average over fmaps and pixels.\n",
        "    y = F.mean(y, axis=[2])                         # [Mn11] Split channels into c channel groups\n",
        "    y = F.tile(y, [group_size, 1, s[2], s[3]])             # [NnHW]  Replicate over group and pixels.\n",
        "    return F.concatenate(x, y, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWKtQZHKBMMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------------------------------------\n",
        "#application of the activation function\n",
        "def leaky_relu(x):\n",
        "    return functools.partial(F.leaky_relu, alpha = 0.2)(x)\n",
        "#--------------------------------------\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naBLBfSABOk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------------------------------------\n",
        "# defining the pixel normalization which is probably used in the Discriminator network\n",
        "def pixel_norm(x, epsilon = 1e-8):\n",
        "    mean1 = F.mean(F.pow_scalar(x, 2.0), axis = 1, keepdims = True)\n",
        "    new_mean1 = F.add_scalar(mean1, epsilon)\n",
        "    denominator = F.pow_scalar(new_mean1, 0.5)\n",
        "    x = F.div2(x, denominator)\n",
        "    return x\n",
        "\n",
        "#--------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0k_dPoBQbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------------------------------------------------------\n",
        "#Defining the Instance Normalization which is used in the Synthesis Generator Network with the format NCHW of the x   Change this FUnction i.e. Instance Normalization..\n",
        "def instance_norm(x, epsilon = 1e-8):\n",
        "    assert len(x.shape) == 4\n",
        "    with nn.parameter_scope('InstanceNorm'):\n",
        "        x1 = compute_channel_mean(x)\n",
        "        x = x - x1\n",
        "        x2 = compute_channel_mean(F.add_scalar(F.pow_scalar(x , 2.0), epsilon))\n",
        "        x2 = F.pow_scalar(x2, 0.5)\n",
        "        x = x / x2\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRhlr-vGBTrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G1(\n",
        "    dlatents_in,\n",
        "    dlatent_size = 512,\n",
        "    num_channels = 3,\n",
        "    resolution = 256,\n",
        "    fmap_base = 8192,\n",
        "    fmap_decay = 1.0,\n",
        "    fmap_max = 512,\n",
        "    use_style = True,\n",
        "    const_input_layer = True,\n",
        "    use_noise = True,\n",
        "    randomize_noise = True,\n",
        "    nonlinearity = 'lrelu',\n",
        "    use_wscale = True,\n",
        "    use_pixel_norm = False,\n",
        "    use_instance_norm = True,\n",
        "    dtype = 'float32',\n",
        "    fused_scale = True,\n",
        "    blur_filter = [1,2,1],\n",
        "    structure = 'linear',\n",
        "    is_template_graph = False,\n",
        "    force_clean_graph = False,\n",
        "    **_kwargs):\n",
        "    \n",
        "    with nn.parameter_scope('G_synthesis'):\n",
        "        resolution_log2 = int(np.log2(resolution))\n",
        "        assert resolution>=4 and resolution == 2 ** (resolution_log2)\n",
        "\n",
        "        def nf(stage):\n",
        "            return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)\n",
        "\n",
        "        def blur(x):\n",
        "            if blur_filter:\n",
        "                return blur2d(x, blur_filter)\n",
        "            else:\n",
        "                return x\n",
        "\n",
        "        if is_template_graph:\n",
        "            force_clean_graph = True\n",
        "\n",
        "        if force_clean_graph:\n",
        "            randomize_noise = False\n",
        "\n",
        "        if structure == 'auto':\n",
        "            if force_clean_graph:\n",
        "                structure = 'linear'\n",
        "            else:\n",
        "                structure = 'recursive'\n",
        "        #structure = 'linear' if force_clean_graph else 'recursive'\n",
        "\n",
        "        act, gain = {'relu' : (F.relu, np.sqrt(2)), 'lrelu' : (leaky_relu, np.sqrt(2))}[nonlinearity]\n",
        "        num_layers = 2 * resolution_log2 - 2\n",
        "    \n",
        "        if use_style:\n",
        "            num_styles = num_layers\n",
        "        else:\n",
        "            num_styles = 1\n",
        "\n",
        "        images_out = None\n",
        "\n",
        "        lod_in = 0\n",
        "\n",
        "        noise_inputs = []\n",
        "        if use_noise:\n",
        "            for layer_idx in range(num_layers):\n",
        "                res = layer_idx // 2 + 2\n",
        "                shape = [1, use_noise, 2 ** (res), 2 ** (res)]\n",
        "                noise_inputs.append(nn.parameter.get_parameter_or_create('noise{}'.format(layer_idx), shape = shape, initializer = I.NormalInitializer(), need_grad = True))\n",
        "        \n",
        "        a1 = []\n",
        "        a11 = []\n",
        "        a12 = []\n",
        "        a2 = []\n",
        "        a3 = []\n",
        "        a4 = []\n",
        "        a5 = []\n",
        "        a6 = []\n",
        "        a71 = []\n",
        "        a72 = []\n",
        "        a8 = []\n",
        "        a9 = []\n",
        "        a10 = []\n",
        "        \n",
        "        a1.append(dlatents_in)\n",
        "\n",
        "        def layer_epilogue(x, a2, a3, a4, a5, a6, layer_idx):\n",
        "            if use_noise:\n",
        "                x = apply_noise(x, noise_inputs[layer_idx], randomize_noise = randomize_noise, **_kwargs)\n",
        "                a2.append(x)\n",
        "            x = apply_bias(x)\n",
        "            a3.append(x)\n",
        "            x = act(x)\n",
        "            a4.append(x)\n",
        "            if use_pixel_norm:\n",
        "                x = pixel_norm(x)\n",
        "                print(\"DJ2\")\n",
        "            if use_instance_norm:\n",
        "                x = instance_norm(x)\n",
        "                a5.append(x)\n",
        "            if use_style:\n",
        "                x = style_mod(x, dlatents_in[:, layer_idx], use_wscale = use_wscale)\n",
        "                a6.append(x)\n",
        "            return x\n",
        "\n",
        "        def torgb(res, a71, a72, x): # res = 2..resolution_log2\n",
        "            lod = resolution_log2 - res\n",
        "            with nn.parameter_scope('ToRGB_lod{}'.format(lod)):\n",
        "                x = conv2d(x, fmaps=num_channels, kernel=1, gain=1, use_wscale=use_wscale)\n",
        "                a71.append(x)\n",
        "                x = apply_bias(x)\n",
        "                a72.append(x)\n",
        "                return x\n",
        "\n",
        "        def block(res, a1, a2, a3, a4, a5, a6, a11, a12, x): # res = 3..resolution_log2                                      # Change the block function....\n",
        "            with nn.parameter_scope('{}x{}'.format(2**res, 2**res)):\n",
        "                with nn.parameter_scope('Conv0_up'):\n",
        "                    x = upscale2d_conv2d(x, fmaps=nf(res-1), kernel=3, gain=gain, use_wscale=use_wscale, fused_scale=fused_scale)\n",
        "                    a11.append(x)\n",
        "                    x = blur2d(x)\n",
        "                    a12.append(x)\n",
        "                    x = layer_epilogue(x, a2, a3, a4, a5, a6, res*2-4)\n",
        "                with nn.parameter_scope('Conv1'):\n",
        "                    x = conv2d(x, fmaps=nf(res-1), kernel = 3, gain=gain, use_wscale=use_wscale)\n",
        "                    a1.append(x)\n",
        "                    x = layer_epilogue(x, a2, a3, a4, a5, a6, res*2-3)\n",
        "            return x\n",
        "\n",
        "        with nn.parameter_scope('4 X 4'):\n",
        "            if const_input_layer:\n",
        "                with nn.parameter_scope('Const'):\n",
        "                    x = nn.parameter.get_parameter_or_create(name = 'const', shape = [1, nf(1), 4, 4], initializer = I.ConstantInitializer(value = 1))\n",
        "                    a1.append(x)\n",
        "                    x = layer_epilogue(F.tile(x, [dlatents_in.shape[0], 1, 1, 1]), a2, a3, a4, a5, a6, 0)\n",
        "            else:\n",
        "                with nn.parameter_scope('Dense'):\n",
        "                    x = dense(dlatents_in[:, 0], fmaps=nf(1)*16, gain=gain/4, use_wscale=use_wscale) \n",
        "                    x = F.reshape(x, [-1, nf(1), 4, 4])\n",
        "                    x = layer_epilogue(x, a2, a3, a4, a5, a6, layer_idx=0)\n",
        "            with nn.parameter_scope('Conv'):\n",
        "                x = conv2d(x, fmaps=nf(1), kernel=3, gain=gain, use_wscale=use_wscale)\n",
        "                a1.append(x)\n",
        "                x = layer_epilogue(x, a2, a3, a4, a5, a6, 1)\n",
        "\n",
        "        if structure == 'fixed':\n",
        "            for res in range(3, resolution_log2 + 1):\n",
        "                x = block(res, a1, a2, a3, a4, a5, a6, x)\n",
        "                images_out = torgb(resolution_log2, a7, x)\n",
        "\n",
        "        if structure == 'linear':\n",
        "            images_out = torgb(2, a71, a72, x)\n",
        "            a10.append(images_out)\n",
        "            for res in range(3, resolution_log2 + 1):\n",
        "                l1 = resolution_log2 - res\n",
        "                lod = l1\n",
        "                x = block(res, a1, a2, a3, a4, a5, a6, a11, a12, x)\n",
        "                img = torgb(res, a71, a72, x)\n",
        "                images_out = upscale2d(images_out)\n",
        "                with nn.parameter_scope('Grow_lod%d' % l1):\n",
        "                    images_out1 = lerp(img, images_out, lod_in- lod)\n",
        "                    a10.append(images_out1)\n",
        "\n",
        "\n",
        "        a8.append(a1)\n",
        "        a8.append(a11)\n",
        "        a8.append(a12)\n",
        "        a8.append(a2)\n",
        "        a8.append(a3)\n",
        "        a8.append(a4)\n",
        "        a8.append(a5)\n",
        "        a8.append(a6)\n",
        "        a8.append(a71)\n",
        "        a8.append(a72)\n",
        "        a8.append(a10)\n",
        "\n",
        "        return a8, F.identity(images_out1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxCN3cE9GVEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(\"noise.txt\", \"rb\") as fp:   \n",
        "   noise = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkKxOkccGcO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"const.txt\", \"rb\") as fp:   \n",
        "   const = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcPyQv7DGgT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"input1.txt\", \"rb\") as fp:   \n",
        "   input1 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Glf6iSKLuAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights1.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights1 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj1n-4aTiL_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights2.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights2 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vNrBSY31GBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights3.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights3 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XXf04hh1GJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights4.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights4 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKOUjrNX1GMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights5.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights5 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsZDv3zk1GSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights6.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights6 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaKzhjbT1IeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"initial_conv_weights7.txt\", \"rb\") as fp:   \n",
        "   initial_conv_weights7 = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFMG7iw0G63N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input12 = input1[0]\n",
        "input12 = nn.Variable.from_numpy_array(input12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrUft0NkAqzf",
        "colab_type": "code",
        "outputId": "6ae9f4a4-1fcb-45c8-aab7-c5c7892f5514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Printing the Inputs:\n",
        "print(input12[0][0][0].d)\n",
        "print(input12[0][0][1].d)\n",
        "print(input12[0][0][2].d)\n",
        "print(input12[0][0][3].d)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.83128\n",
            "0.2854586\n",
            "0.9196952\n",
            "0.8687711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSidpoTXG7At",
        "colab_type": "code",
        "outputId": "f3f4cf6f-f2b8-4064-adb6-ee74ea6903d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "list1, output1 = G1(input12, num_channels = 3, resolution= 256, randomize_noise = False, use_wscale = False, fused_scale=False, structure='linear')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dj1\n",
            "Dj1\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -5\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -4\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -3\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -2\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -1\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is 0\n",
            "Only a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTQY9zAFG9BG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = nn.get_parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPqBAcxrI7ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = 0 \n",
        "for i, j in ax.items():\n",
        "    if(l==14):\n",
        "        break\n",
        "    j.data.copy_from(nn.Variable.from_numpy_array(noise[l]).data)\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNQmA6L9MR4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = 0\n",
        "l1 = 0\n",
        "for i,j in ax.items():\n",
        "    if(l==19):\n",
        "        break\n",
        "    if(l>=14):\n",
        "        j.data.copy_from(nn.Variable.from_numpy_array(const[l1]).data)\n",
        "        l1 = l1 + 1\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb7lAyFrNHiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = 0\n",
        "l1 = 0\n",
        "for i,j in ax.items():\n",
        "    if(l==26):\n",
        "        break\n",
        "    if(l>=19):\n",
        "        if(l==19 or l==24):\n",
        "            a1 = np.transpose(initial_conv_weights1[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from((nn.Variable.from_numpy_array(a1)).data) \n",
        "        else:\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(initial_conv_weights1[l1]).data)         \n",
        "        l1 = l1 + 1\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSBBv9LDeM8j",
        "colab_type": "code",
        "outputId": "49ea7004-3a4a-45d3-f21e-96464f97b56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "l = 0\n",
        "l1 = 0\n",
        "for i,j in ax.items():\n",
        "    if(l==38):\n",
        "        print(\"value of l is:\", l)\n",
        "        break\n",
        "    if(l>=26):\n",
        "        if(l==26):\n",
        "            a1 = np.transpose(initial_conv_weights2[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data) \n",
        "        elif(l==31):\n",
        "            a1 = np.transpose(initial_conv_weights2[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data)\n",
        "        elif(l==36):\n",
        "            a1 = np.transpose(initial_conv_weights2[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data)\n",
        "        else:\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(initial_conv_weights2[l1]).data)         \n",
        "        l1 = l1 + 1\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of l is: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdLLBLXF1leq",
        "colab_type": "code",
        "outputId": "28f9c506-c86d-4836-98ba-e3e2f878a363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "l = 0\n",
        "l1 = 0\n",
        "for i,j in ax.items():\n",
        "    if(l==50):\n",
        "        print(\"value of l is:\", l)\n",
        "        break\n",
        "    if(l>=38):\n",
        "        if(l==38):\n",
        "            a1 = np.transpose(initial_conv_weights3[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data) \n",
        "        elif(l==43 or l==48):\n",
        "            a1 = np.transpose(initial_conv_weights3[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data)\n",
        "        else:\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(initial_conv_weights3[l1]).data)         \n",
        "        l1 = l1 + 1\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of l is: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-apyfJy1yd-",
        "colab_type": "code",
        "outputId": "8bb16a08-6669-4fc0-84c7-e86db6a9575a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "l = 0\n",
        "l1 = 0\n",
        "for i,j in ax.items():\n",
        "    if(l==62):\n",
        "        print(\"value of l is:\", l)\n",
        "        break\n",
        "    if(l>=50):\n",
        "        if(l==50):\n",
        "            a1 = np.transpose(initial_conv_weights4[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data) \n",
        "        elif(l==55 or l==60):\n",
        "            a1 = np.transpose(initial_conv_weights4[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data)\n",
        "        else:\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(initial_conv_weights4[l1]).data)         \n",
        "        l1 = l1 + 1\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of l is: 62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_rD6JmQ1ymC",
        "colab_type": "code",
        "outputId": "21ed2200-bd90-4750-84ea-059041081179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "l = 0\n",
        "l1 = 0\n",
        "for i,j in ax.items():\n",
        "    if(l==74):\n",
        "        print(\"value of l is:\", l)\n",
        "        break\n",
        "    if(l>=62):\n",
        "        if(l==62):\n",
        "            a1 = np.transpose(initial_conv_weights5[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data) \n",
        "        elif(l==67 or l==72):\n",
        "            a1 = np.transpose(initial_conv_weights5[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data)\n",
        "        else:\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(initial_conv_weights5[l1]).data)         \n",
        "        l1 = l1 + 1\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of l is: 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4iekinG2gBp",
        "colab_type": "code",
        "outputId": "b003238d-b60c-4986-ed9e-890762e9f3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "l = 0\n",
        "l1 = 0\n",
        "for i,j in ax.items():\n",
        "    if(l==86):\n",
        "        print(\"value of l is:\", l)\n",
        "        break\n",
        "    if(l>=74):\n",
        "        if(l==74):\n",
        "            a1 = np.transpose(initial_conv_weights6[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data) \n",
        "        elif(l==79):\n",
        "            a1 = np.transpose(initial_conv_weights6[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data)\n",
        "        elif(l==84):\n",
        "            a1 = np.transpose(initial_conv_weights6[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data)\n",
        "        else:\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(initial_conv_weights6[l1]).data)         \n",
        "        l1 = l1 + 1\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of l is: 86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ7bmpK63mBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = 0\n",
        "l1 = 0\n",
        "for i,j in ax.items():\n",
        "    if(l==98):\n",
        "        print(\"value of l is:\", l)\n",
        "        break\n",
        "    if(l>=86):\n",
        "        if(l==86):\n",
        "            a1 = np.transpose(initial_conv_weights7[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data) \n",
        "        elif(l==91 or l==96):\n",
        "            a1 = np.transpose(initial_conv_weights7[l1], axes = [3, 2, 0, 1])\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(a1).data)\n",
        "        else:\n",
        "            j.data.copy_from(nn.Variable.from_numpy_array(initial_conv_weights7[l1]).data)         \n",
        "        l1 = l1 + 1\n",
        "    l = l + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG-fzS1XNeQW",
        "colab_type": "code",
        "outputId": "ce0b994b-40d4-4489-df75-5b607d757363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "list2, output2 = G1(input12, num_channels = 3, resolution= 256, randomize_noise = False, use_wscale = False, fused_scale=False, structure='linear')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dj1\n",
            "Dj1\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -5\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -4\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -3\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -2\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is -1\n",
            "Only a\n",
            "Dj1\n",
            "Dj1\n",
            "Value of t is 0\n",
            "Only a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgpy5Fk33854",
        "colab_type": "code",
        "outputId": "08cbb2f2-be3a-499d-e261-74973ce7d09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# Printing the Outputs:\n",
        "print(output2[0][0][0][0].d)\n",
        "print(output2[0][0][0][1].d)\n",
        "print(output2[0][0][0][2].d)\n",
        "print(output2[0][0][0][3].d)\n",
        "print()\n",
        "print(output2[0][0][1][0].d)\n",
        "print(output2[0][0][1][1].d)\n",
        "print(output2[0][0][1][2].d)\n",
        "print(output2[0][0][1][3].d)\n",
        "print()\n",
        "print(output2[0][0][2][0].d)\n",
        "print(output2[0][0][2][1].d)\n",
        "print(output2[0][0][2][2].d)\n",
        "print(output2[0][0][2][3].d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.214745\n",
            "-12.6091\n",
            "-23.258469\n",
            "-49.759506\n",
            "\n",
            "22.246475\n",
            "0.50022924\n",
            "-3.6949687\n",
            "-40.752403\n",
            "\n",
            "55.498444\n",
            "43.97695\n",
            "13.625519\n",
            "-38.80551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWE-H3KgE1DZ",
        "colab_type": "code",
        "outputId": "31366f05-5bfa-48ce-97cb-6d45e642073a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "print(output2.d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 1.12147446e+01 -1.26091003e+01 -2.32584686e+01 ...  1.06867874e+02\n",
            "     7.76745300e+01  3.43050308e+01]\n",
            "   [ 2.22464752e+01  5.00229239e-01 -3.69496870e+00 ...  1.77655380e+02\n",
            "     1.37520386e+02  4.82230873e+01]\n",
            "   [ 5.54984436e+01  4.39769516e+01  1.36255188e+01 ...  1.62914917e+02\n",
            "     1.57168686e+02  8.39401779e+01]\n",
            "   ...\n",
            "   [ 4.36366272e+01  6.75754318e+01  2.07843246e+01 ... -1.19093681e+02\n",
            "    -1.15214134e+02 -1.01103683e+02]\n",
            "   [ 1.91865234e+01  4.95323715e+01  4.82497482e+01 ... -1.17203270e+02\n",
            "    -1.32540405e+02 -1.13222588e+02]\n",
            "   [ 5.55048037e+00  3.08207169e+01  4.63837051e+01 ... -1.45084747e+02\n",
            "    -1.49820435e+02 -9.18438950e+01]]\n",
            "\n",
            "  [[-5.28250923e+01 -8.65906830e+01 -8.80172729e+01 ... -3.66232777e+00\n",
            "    -3.00698757e+01 -4.28526459e+01]\n",
            "   [-4.97590294e+01 -7.17598267e+01 -6.79165497e+01 ...  2.75078411e+01\n",
            "     1.57569742e+01 -2.65963745e+01]\n",
            "   [-1.87806778e+01 -2.57676392e+01 -6.90390320e+01 ...  8.95478535e+00\n",
            "     2.10470390e+01  5.62057972e+00]\n",
            "   ...\n",
            "   [ 1.60542023e+02  2.96271820e+02  2.52315643e+02 ... -1.20134346e+02\n",
            "    -1.05394463e+02 -1.15921906e+02]\n",
            "   [ 1.20154434e+02  2.30599396e+02  2.55820801e+02 ... -9.13967819e+01\n",
            "    -1.10822632e+02 -1.21199768e+02]\n",
            "   [ 4.61152382e+01  1.14317429e+02  1.51221771e+02 ... -1.48825775e+02\n",
            "    -1.52787109e+02 -1.03649139e+02]]\n",
            "\n",
            "  [[-9.89136353e+01 -1.32320526e+02 -1.27267632e+02 ... -8.93836746e+01\n",
            "    -9.04184723e+01 -9.91318207e+01]\n",
            "   [-9.75772400e+01 -1.11994446e+02 -1.03604919e+02 ... -1.11267799e+02\n",
            "    -9.42341843e+01 -7.72971344e+01]\n",
            "   [-6.37886543e+01 -5.74688988e+01 -1.10962891e+02 ... -1.40063522e+02\n",
            "    -1.14637268e+02 -7.37126007e+01]\n",
            "   ...\n",
            "   [ 3.43293793e+02  6.42490784e+02  6.83225159e+02 ... -4.84610252e+01\n",
            "    -5.24715919e+01 -7.50533524e+01]\n",
            "   [ 2.65725983e+02  4.96046906e+02  6.00579712e+02 ... -3.17486839e+01\n",
            "    -6.58521271e+01 -8.59139252e+01]\n",
            "   [ 1.15537605e+02  2.51748047e+02  3.38155182e+02 ... -8.47264099e+01\n",
            "    -1.06720009e+02 -1.01296616e+02]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQai9XcyCkKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}